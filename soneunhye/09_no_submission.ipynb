{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries\n",
    "%pip install --upgrade timm albumentations -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"Random seed set to {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CFG = {\n",
    "    'IMG_SIZE': 384,\n",
    "    'BATCH_SIZE': 8,\n",
    "    'NUM_CLASSES': 17,\n",
    "    'EPOCHS': 30,\n",
    "    'LR': 5e-5,\n",
    "    'WEIGHT_DECAY': 0.01,\n",
    "    'MODEL_NAME': 'convnextv2_base.fcmae_ft_in22k_in1k_384',\n",
    "    'DROPOUT': 0.6,\n",
    "    'MIXUP_ALPHA': 0.3,\n",
    "    'FOCAL_GAMMA': 2.0,\n",
    "    'FOCAL_ALPHA': 1.0,\n",
    "    'WARMUP_EPOCHS': 5,\n",
    "    'USE_TTA': True,\n",
    "    'N_FOLDS': 5,\n",
    "    'BASE_DIR': '/home/realtheai/cv_competetion',\n",
    "    'TRAIN_CSV': '/home/realtheai/cv_competetion/data/train.csv',\n",
    "    'SAMPLE_SUBMISSION_CSV': '/home/realtheai/cv_competetion/data/sample_submission.csv',\n",
    "    'TRAIN_IMG_DIR': '/home/realtheai/cv_competetion/data/train',\n",
    "    'TEST_IMG_DIR': '/home/realtheai/cv_competetion/data/test',\n",
    "    'DEVICE': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Configuration - Strategy A\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {CFG['MODEL_NAME']}\")\n",
    "print(f\"Image Size: {CFG['IMG_SIZE']} (↑ from 224)\")\n",
    "print(f\"Batch Size: {CFG['BATCH_SIZE']} (↓ due to larger images)\")\n",
    "print(f\"Epochs: {CFG['EPOCHS']}\")\n",
    "print(f\"Learning Rate: {CFG['LR']} (↓ from 1e-4)\")\n",
    "print(f\"Warmup Epochs: {CFG['WARMUP_EPOCHS']}\")\n",
    "print(f\"Dropout: {CFG['DROPOUT']} (↑ from 0.5)\")\n",
    "print(f\"Mixup Alpha: {CFG['MIXUP_ALPHA']}\")\n",
    "print(f\"Focal Loss Gamma: {CFG['FOCAL_GAMMA']}\")\n",
    "print(f\"TTA: {CFG['USE_TTA']}\")\n",
    "print(f\"N-Folds: {CFG['N_FOLDS']}\")\n",
    "print(f\"Device: {CFG['DEVICE']}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with Mixup support\n",
    "class DocumentDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None, is_test=False, mixup_alpha=0.0):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.mixup_alpha = mixup_alpha\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx]['ID']\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        img = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        \n",
    "        if self.is_test:\n",
    "            return img\n",
    "        \n",
    "        target = self.df.iloc[idx]['target']\n",
    "        \n",
    "        if self.mixup_alpha > 0 and random.random() < 0.5:\n",
    "            mix_idx = random.randint(0, len(self.df) - 1)\n",
    "            mix_img_name = self.df.iloc[mix_idx]['ID']\n",
    "            mix_img_path = os.path.join(self.img_dir, mix_img_name)\n",
    "            mix_img = np.array(Image.open(mix_img_path).convert('RGB'))\n",
    "            \n",
    "            if self.transform:\n",
    "                mix_img = self.transform(image=mix_img)['image']\n",
    "            \n",
    "            lam = np.random.beta(self.mixup_alpha, self.mixup_alpha)\n",
    "            img = lam * img + (1 - lam) * mix_img\n",
    "            mix_target = self.df.iloc[mix_idx]['target']\n",
    "            \n",
    "            return img, target, mix_target, lam\n",
    "        \n",
    "        return img, target, target, 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation - Redesigned for Train/Test quality gap\n",
    "trn_transform = A.Compose([\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    A.OneOf([\n",
    "        A.GaussianBlur(blur_limit=(3, 11), p=1.0),\n",
    "        A.MotionBlur(blur_limit=9, p=1.0),\n",
    "        A.MedianBlur(blur_limit=7, p=1.0),\n",
    "    ], p=0.5),\n",
    "    A.ImageCompression(quality_lower=50, quality_upper=100, p=0.5),\n",
    "    A.Downscale(scale_min=0.6, scale_max=0.8, p=0.8),\n",
    "    A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.3),\n",
    "    A.GaussNoise(var_limit=(10, 50), p=0.4),\n",
    "    A.Rotate(limit=5, p=0.3),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=5, p=0.3),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "    A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=15, p=0.3),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "tst_transform = A.Compose([\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "print(\"Augmentation setup complete - Redesigned for quality gap\")\n",
    "print(\"  - Blur: 0.5 (reduced from 0.8)\")\n",
    "print(\"  - Downscale: 0.8 with 0.6-0.8 range (stronger)\")\n",
    "print(\"  - Sharpen: 0.3 (new)\")\n",
    "print(\"  - Other aug probabilities reduced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model & Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal Loss for hard samples\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1.0, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "# ConvNeXt V2 Model\n",
    "class ConvNeXtClassifier(nn.Module):\n",
    "    def __init__(self, model_name='convnextv2_base.fcmae_ft_in22k_in1k_384', num_classes=17, dropout=0.6):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=True, num_classes=0)\n",
    "        in_features = self.backbone.num_features\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.backbone(x))\n",
    "\n",
    "print(f\"Model: {CFG['MODEL_NAME']}\")\n",
    "print(f\"Focal Loss: alpha={CFG['FOCAL_ALPHA']}, gamma={CFG['FOCAL_GAMMA']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(CFG['TRAIN_CSV'])\n",
    "test_df = pd.read_csv(CFG['SAMPLE_SUBMISSION_CSV'])\n",
    "meta_df = pd.read_csv(f\"{CFG['BASE_DIR']}/data/meta.csv\")\n",
    "\n",
    "print(f\"\\nData loaded:\")\n",
    "print(f\"  Train: {len(train_df)} samples\")\n",
    "print(f\"  Test: {len(test_df)} samples\")\n",
    "print(f\"  Classes: {CFG['NUM_CLASSES']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training functions with Mixup support\n",
    "def train_epoch(model, loader, optimizer, criterion, scheduler, device, current_epoch, warmup_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for imgs, targets, mix_targets, lam in tqdm(loader, desc=\"Training\"):\n",
    "        imgs = imgs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        mix_targets = mix_targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        \n",
    "        loss = lam.mean() * criterion(outputs, targets) + (1 - lam.mean()) * criterion(outputs, mix_targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if current_epoch >= warmup_epochs:\n",
    "            scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, targets, _, _ in tqdm(loader, desc=\"Validation\"):\n",
    "            imgs, targets = imgs.to(device), targets.to(device)\n",
    "            outputs = model(imgs)\n",
    "            \n",
    "            total_loss += criterion(outputs, targets).item()\n",
    "            all_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    return avg_loss, accuracy, f1, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross Validation\n",
    "skf = StratifiedKFold(n_splits=CFG['N_FOLDS'], shuffle=True, random_state=SEED)\n",
    "fold_results = []\n",
    "oof_preds = np.zeros(len(train_df))\n",
    "test_preds_proba = np.zeros((len(test_df), CFG['NUM_CLASSES'], CFG['N_FOLDS']))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Starting {CFG['N_FOLDS']}-Fold Cross Validation - Strategy A\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Fold {fold + 1}/{CFG['N_FOLDS']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    trn_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    print(f\"Train: {len(trn_df)} samples | Val: {len(val_df)} samples\")\n",
    "    \n",
    "    trn_dataset = DocumentDataset(trn_df, CFG['TRAIN_IMG_DIR'], trn_transform, mixup_alpha=CFG['MIXUP_ALPHA'])\n",
    "    val_dataset = DocumentDataset(val_df, CFG['TRAIN_IMG_DIR'], tst_transform, mixup_alpha=0.0)\n",
    "    \n",
    "    trn_loader = DataLoader(trn_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    model = ConvNeXtClassifier(CFG['MODEL_NAME'], CFG['NUM_CLASSES'], CFG['DROPOUT']).to(CFG['DEVICE'])\n",
    "    criterion = FocalLoss(alpha=CFG['FOCAL_ALPHA'], gamma=CFG['FOCAL_GAMMA'])\n",
    "    optimizer = AdamW(model.parameters(), lr=CFG['LR'], weight_decay=CFG['WEIGHT_DECAY'])\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=len(trn_loader) * (CFG['EPOCHS'] - CFG['WARMUP_EPOCHS']), eta_min=1e-7)\n",
    "    \n",
    "    best_f1, best_epoch, patience = 0, 0, 0\n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS'] + 1):\n",
    "        train_loss = train_epoch(model, trn_loader, optimizer, criterion, scheduler, CFG['DEVICE'], epoch, CFG['WARMUP_EPOCHS'])\n",
    "        val_loss, val_acc, val_f1, val_preds, _ = validate(model, val_loader, criterion, CFG['DEVICE'])\n",
    "        \n",
    "        if val_f1 > best_f1:\n",
    "            best_f1, best_epoch, patience = val_f1, epoch, 0\n",
    "            torch.save(model.state_dict(), f\"{CFG['BASE_DIR']}/fold{fold+1}_best.pth\")\n",
    "            oof_preds[val_idx] = val_preds\n",
    "            warmup_status = \"[Warmup]\" if epoch <= CFG['WARMUP_EPOCHS'] else \"\"\n",
    "            print(f\"Epoch {epoch:2d} {warmup_status}: Loss {train_loss:.4f} | Val Loss {val_loss:.4f} Acc {val_acc:.4f} F1 {val_f1:.4f} | Best {best_f1:.4f} (SAVED)\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            warmup_status = \"[Warmup]\" if epoch <= CFG['WARMUP_EPOCHS'] else \"\"\n",
    "            print(f\"Epoch {epoch:2d} {warmup_status}: Loss {train_loss:.4f} | Val Loss {val_loss:.4f} Acc {val_acc:.4f} F1 {val_f1:.4f} | Best {best_f1:.4f} (Patience {patience}/7)\")\n",
    "        \n",
    "        if patience >= 7:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "    \n",
    "    fold_results.append({'fold': fold + 1, 'best_f1': best_f1, 'best_epoch': best_epoch})\n",
    "    print(f\"\\nFold {fold + 1} complete: Best F1 = {best_f1:.4f} at epoch {best_epoch}\")\n",
    "    \n",
    "    # Test inference\n",
    "    print(f\"\\nRunning test inference...\")\n",
    "    model.load_state_dict(torch.load(f\"{CFG['BASE_DIR']}/fold{fold+1}_best.pth\"))\n",
    "    model.eval()\n",
    "    \n",
    "    test_dataset = DocumentDataset(test_df, CFG['TEST_IMG_DIR'], tst_transform, is_test=True, mixup_alpha=0.0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=4)\n",
    "    \n",
    "    fold_test_proba = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in tqdm(test_loader, desc=f\"Fold {fold+1} Test\"):\n",
    "            proba = F.softmax(model(imgs.to(CFG['DEVICE'])), dim=1)\n",
    "            fold_test_proba.append(proba.cpu().numpy())\n",
    "    \n",
    "    test_preds_proba[:, :, fold] = np.concatenate(fold_test_proba, axis=0)\n",
    "    print(f\"Fold {fold + 1} test predictions complete\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"All folds complete!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Results & Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Final Results - Strategy A\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nFold Results:\")\n",
    "for result in fold_results:\n",
    "    print(f\"  Fold {result['fold']}: F1 = {result['best_f1']:.4f} (Epoch {result['best_epoch']})\")\n",
    "\n",
    "mean_f1 = np.mean([r['best_f1'] for r in fold_results])\n",
    "std_f1 = np.std([r['best_f1'] for r in fold_results])\n",
    "oof_f1 = f1_score(train_df['target'], oof_preds, average='macro')\n",
    "oof_acc = accuracy_score(train_df['target'], oof_preds)\n",
    "\n",
    "print(f\"\\nCross-Validation:\")\n",
    "print(f\"  Mean Fold F1: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "print(f\"  OOF F1: {oof_f1:.4f}\")\n",
    "print(f\"  OOF Accuracy: {oof_acc:.4f}\")\n",
    "\n",
    "\n",
    "# Submission\n",
    "final_preds = test_preds_proba.mean(axis=2).argmax(axis=1)\n",
    "submission = test_df.copy()\n",
    "submission['target'] = final_preds\n",
    "submission.to_csv(f\"{CFG['BASE_DIR']}/submission.csv\", index=False)\n",
    "\n",
    "print(f\"\\nSubmission file saved: submission.csv\")\n",
    "print(f\"Total predictions: {len(submission)}\")\n",
    "\n",
    "# Prediction distribution\n",
    "print(f\"\\nPrediction Distribution:\")\n",
    "pred_counts = pd.Series(final_preds).value_counts().sort_index()\n",
    "for class_id, count in pred_counts.items():\n",
    "    class_name = meta_df[meta_df['target'] == class_id]['class_name'].values[0]\n",
    "    print(f\"  Class {class_id:2d} ({class_name[:25]:25s}): {count:4d}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Complete!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualization: K-Fold Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: K-Fold Results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "fold_nums = [r['fold'] for r in fold_results]\n",
    "fold_f1s = [r['best_f1'] for r in fold_results]\n",
    "fold_epochs = [r['best_epoch'] for r in fold_results]\n",
    "\n",
    "# Fold F1 Scores\n",
    "axes[0, 0].bar(fold_nums, fold_f1s, color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6'])\n",
    "axes[0, 0].axhline(y=np.mean(fold_f1s), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(fold_f1s):.4f}')\n",
    "axes[0, 0].axhline(y=0.8827, color='orange', linestyle=':', linewidth=2, label='09_code OOF: 0.8827')\n",
    "axes[0, 0].set_title('Best F1 Score per Fold (Strategy A)', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Fold')\n",
    "axes[0, 0].set_ylabel('F1 Score')\n",
    "axes[0, 0].set_ylim([min(fold_f1s) - 0.05, max(max(fold_f1s), 0.89) + 0.02])\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3, axis='y')\n",
    "for i, (f1, epoch) in enumerate(zip(fold_f1s, fold_epochs)):\n",
    "    axes[0, 0].text(fold_nums[i], f1 + 0.01, f'{f1:.4f}\\n(E{epoch})', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Best Epochs\n",
    "axes[0, 1].bar(fold_nums, fold_epochs, color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6'])\n",
    "axes[0, 1].axhline(y=np.mean(fold_epochs), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(fold_epochs):.1f}')\n",
    "axes[0, 1].axhline(y=CFG['WARMUP_EPOCHS'], color='green', linestyle=':', linewidth=2, label=f'Warmup: {CFG[\"WARMUP_EPOCHS\"]}')\n",
    "axes[0, 1].set_title('Best Epoch per Fold', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Fold')\n",
    "axes[0, 1].set_ylabel('Epoch')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3, axis='y')\n",
    "for i, epoch in enumerate(fold_epochs):\n",
    "    axes[0, 1].text(fold_nums[i], epoch + 0.3, f'{epoch}', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# F1 Distribution\n",
    "axes[1, 0].boxplot([fold_f1s], labels=['All Folds'], widths=0.5)\n",
    "axes[1, 0].scatter([1]*len(fold_f1s), fold_f1s, c=['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6'], s=100, alpha=0.6, edgecolors='black', linewidth=1.5)\n",
    "axes[1, 0].set_title('F1 Score Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('F1 Score')\n",
    "axes[1, 0].grid(alpha=0.3, axis='y')\n",
    "axes[1, 0].text(1.3, np.mean(fold_f1s), f'Mean: {np.mean(fold_f1s):.4f}\\nStd: {np.std(fold_f1s):.4f}\\nOOF: {oof_f1:.4f}', fontsize=11, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# Summary Table\n",
    "axes[1, 1].axis('off')\n",
    "summary_data = [\n",
    "    ['Metric', 'Value'],\n",
    "    ['─' * 20, '─' * 20],\n",
    "    ['Mean F1', f'{np.mean(fold_f1s):.4f}'],\n",
    "    ['Std F1', f'{np.std(fold_f1s):.4f}'],\n",
    "    ['Min F1', f'{min(fold_f1s):.4f}'],\n",
    "    ['Max F1', f'{max(fold_f1s):.4f}'],\n",
    "    ['─' * 20, '─' * 20],\n",
    "    ['OOF F1', f'{oof_f1:.4f}'],\n",
    "    ['OOF Accuracy', f'{oof_acc:.4f}'],\n",
    "    ['─' * 20, '─' * 20],\n",
    "    ['09_code OOF', '0.8827'],\n",
    "    ['09_code LB', '0.6669'],\n",
    "]\n",
    "\n",
    "table = axes[1, 1].table(cellText=summary_data, cellLoc='left', loc='center', colWidths=[0.6, 0.4])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1, 2.2)\n",
    "\n",
    "for i in range(2):\n",
    "    table[(0, i)].set_facecolor('#3498db')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "    table[(7, i)].set_facecolor('#2ecc71')\n",
    "    table[(7, i)].set_text_props(weight='bold')\n",
    "    table[(8, i)].set_facecolor('#2ecc71')\n",
    "    table[(8, i)].set_text_props(weight='bold')\n",
    "\n",
    "axes[1, 1].set_title('Performance Summary', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CFG['BASE_DIR']}/kfold_results.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nVisualization saved: kfold_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Wrong Predictions Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrong Predictions Analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Wrong Predictions Analysis\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "oof_preds_int = oof_preds.astype(int)\n",
    "actual_labels = train_df['target'].values.astype(int)\n",
    "\n",
    "wrong_mask = (oof_preds_int != actual_labels)\n",
    "wrong_df = train_df[wrong_mask].copy()\n",
    "wrong_df['predicted'] = oof_preds_int[wrong_mask]\n",
    "wrong_df['actual'] = actual_labels[wrong_mask]\n",
    "\n",
    "print(f\"\\nTotal wrong: {len(wrong_df)}/{len(train_df)} (Accuracy: {(1 - len(wrong_df)/len(train_df))*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nWrong by class:\")\n",
    "wrong_by_class = wrong_df.groupby('actual').size().sort_values(ascending=False)\n",
    "for class_id, count in wrong_by_class.items():\n",
    "    class_id = int(class_id)\n",
    "    class_name = meta_df[meta_df['target'] == class_id]['class_name'].values[0]\n",
    "    total_in_class = (train_df['target'] == class_id).sum()\n",
    "    error_rate = (count / total_in_class) * 100\n",
    "    print(f\"  Class {class_id:2d} ({class_name[:25]:25s}): {count:2d}/{total_in_class:3d} ({error_rate:5.1f}% error)\")\n",
    "\n",
    "print(f\"\\nMost confused pairs:\")\n",
    "confusion_pairs = wrong_df.groupby(['actual', 'predicted']).size().sort_values(ascending=False).head(10)\n",
    "for idx, ((actual, pred), count) in enumerate(confusion_pairs.items(), 1):\n",
    "    actual = int(actual)\n",
    "    pred = int(pred)\n",
    "    actual_name = meta_df[meta_df['target'] == actual]['class_name'].values[0]\n",
    "    pred_name = meta_df[meta_df['target'] == pred]['class_name'].values[0]\n",
    "    print(f\"  {idx:2d}. Class {actual:2d} ({actual_name[:20]:20s}) -> Class {pred:2d} ({pred_name[:20]:20s}): {count}\")\n",
    "\n",
    "# Visualize wrong predictions\n",
    "n_samples = min(12, len(wrong_df))\n",
    "sample_indices = np.random.choice(len(wrong_df), n_samples, replace=False)\n",
    "samples = wrong_df.iloc[sample_indices]\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (ax, (_, row)) in enumerate(zip(axes, samples.iterrows())):\n",
    "    img_path = os.path.join(CFG['TRAIN_IMG_DIR'], row['ID'])\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    \n",
    "    actual = int(row['actual'])\n",
    "    predicted = int(row['predicted'])\n",
    "    actual_name = meta_df[meta_df['target'] == actual]['class_name'].values[0]\n",
    "    pred_name = meta_df[meta_df['target'] == predicted]['class_name'].values[0]\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"Actual: {actual} ({actual_name[:15]})\\nPredicted: {predicted} ({pred_name[:15]})\", fontsize=9, color='red', fontweight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CFG['BASE_DIR']}/wrong_predictions.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nWrong predictions saved: wrong_predictions.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Confusion Matrix\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "cm = confusion_matrix(actual_labels, oof_preds_int)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 14))\n",
    "im = ax.imshow(cm, cmap='Blues', interpolation='nearest')\n",
    "ax.set_title('Confusion Matrix (OOF - 5-Fold) - Strategy A', fontsize=18, fontweight='bold', pad=20)\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Count', fontsize=12)\n",
    "\n",
    "tick_labels = []\n",
    "for i in range(CFG['NUM_CLASSES']):\n",
    "    class_name = meta_df[meta_df['target']==i]['class_name'].values[0]\n",
    "    if len(class_name) > 15:\n",
    "        class_name = class_name[:12] + '...'\n",
    "    tick_labels.append(f\"{i}\\n{class_name}\")\n",
    "\n",
    "ax.set_xticks(range(CFG['NUM_CLASSES']))\n",
    "ax.set_yticks(range(CFG['NUM_CLASSES']))\n",
    "ax.set_xticklabels(tick_labels, rotation=45, ha='right', fontsize=9)\n",
    "ax.set_yticklabels(tick_labels, fontsize=9)\n",
    "ax.set_xlabel('Predicted Label', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('True Label', fontsize=14, fontweight='bold')\n",
    "\n",
    "threshold = cm.max() / 2\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        if i == j:\n",
    "            color = 'darkgreen' if cm[i, j] > threshold else 'green'\n",
    "            weight = 'bold'\n",
    "        else:\n",
    "            color = 'white' if cm[i, j] > threshold else 'black'\n",
    "            weight = 'normal'\n",
    "        \n",
    "        if cm[i, j] > 0:\n",
    "            ax.text(j, i, str(cm[i, j]), ha='center', va='center', color=color, fontsize=9, fontweight=weight)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CFG['BASE_DIR']}/confusion_matrix.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nConfusion Matrix saved: confusion_matrix.png\")\n",
    "\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"  Total samples: {cm.sum():.0f}\")\n",
    "print(f\"  Correct: {np.trace(cm):.0f}\")\n",
    "print(f\"  Wrong: {cm.sum() - np.trace(cm):.0f}\")\n",
    "print(f\"  Accuracy: {np.trace(cm) / cm.sum() * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\nClass Recall:\")\n",
    "for i in range(CFG['NUM_CLASSES']):\n",
    "    class_name = meta_df[meta_df['target']==i]['class_name'].values[0]\n",
    "    total = cm[i, :].sum()\n",
    "    correct = cm[i, i]\n",
    "    recall = (correct / total * 100) if total > 0 else 0\n",
    "    print(f\"  Class {i:2d} ({class_name[:25]:25s}): {correct:3.0f}/{total:3.0f} ({recall:5.1f}%)\")\n",
    "\n",
    "print(f\"\\nMost confused pairs (top 5):\")\n",
    "confusion_list = []\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        if i != j and cm[i, j] > 0:\n",
    "            confusion_list.append((i, j, cm[i, j]))\n",
    "\n",
    "confusion_list.sort(key=lambda x: x[2], reverse=True)\n",
    "for idx, (true_class, pred_class, count) in enumerate(confusion_list[:5], 1):\n",
    "    true_name = meta_df[meta_df['target']==true_class]['class_name'].values[0]\n",
    "    pred_name = meta_df[meta_df['target']==pred_class]['class_name'].values[0]\n",
    "    print(f\"  {idx}. Class {true_class:2d} ({true_name[:20]:20s}) -> Class {pred_class:2d} ({pred_name[:20]:20s}): {count:.0f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
