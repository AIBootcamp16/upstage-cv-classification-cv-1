{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "\n",
    "# ê¸°ì¡´ PaddlePaddle ì™„ì „ ì œê±°\n",
    "%pip uninstall -y paddlepaddle paddlepaddle-gpu paddleocr\n",
    "\n",
    "# âœ… PaddlePaddle 3.2.0 (CUDA 12.6+ í˜¸í™˜) + PaddleOCR 3.3.1\n",
    "# ì¤‘ìš”: PaddlePaddle 2.6.2ëŠ” PaddleOCR 3.xì™€ API ë¹„í˜¸í™˜!\n",
    "# â†’ PaddlePaddle 3.2.0ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ í•„ìˆ˜\n",
    "\n",
    "# PaddlePaddle GPU 3.2.0 ì„¤ì¹˜ (CUDA 12.6+ í˜¸í™˜)\n",
    "%pip install paddlepaddle-gpu==3.2.0 -i https://www.paddlepaddle.org.cn/packages/stable/cu126/ -q\n",
    "\n",
    "# í˜¸í™˜ì„± íŒ¨í‚¤ì§€ ì„¤ì¹˜ (setuptools ì˜¤ë¥˜ ë°©ì§€)\n",
    "%pip install --upgrade setuptools backports.tarfile -q\n",
    "\n",
    "# PaddleOCR ë° ê¸°íƒ€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "%pip install --upgrade paddleocr timm albumentations -q\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "from paddleocr import PaddleOCR  # ğŸ”¥ PaddleOCR (ë¹ ë¥¸ í•œêµ­ì–´ OCR)\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time  # í•™ìŠµ ì‹œê°„ ì¸¡ì •ìš©\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import AdamW  # Adam â†’ AdamW (Weight Decay)\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from scipy import stats  # K-Fold ì•™ìƒë¸”ìš©\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ì‹œë“œ ê³ ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œë“œ ê³ ì •\n",
    "SEED = 42\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyperparameters (EDA ê²°ê³¼ ë°˜ì˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== í•˜ì´í¼íŒŒë¼ë¯¸í„° (Best Practice! ğŸ”¥) ========== #\n",
    "CFG = {\n",
    "    # ë°ì´í„°\n",
    "    'IMG_SIZE': 224,  # Swin Transformer ê¸°ë³¸ê°’\n",
    "    'BATCH_SIZE': 16,  # Swinì€ EfficientNetë³´ë‹¤ ê°€ë²¼ì›€\n",
    "    'NUM_CLASSES': 17,\n",
    "    \n",
    "    # í•™ìŠµ\n",
    "    'EPOCHS': 20,  # Foldë‹¹ 20 Epoch\n",
    "    'LR': 1e-4,  # Swin Transformer Fine-tuning LR\n",
    "    'WEIGHT_DECAY': 0.01,  # ê°•í™”\n",
    "    \n",
    "    # ëª¨ë¸\n",
    "    'MODEL_NAME': 'swin_base_patch4_window7_224',  # ğŸ”¥ Swin Transformer!\n",
    "    'DROPOUT': 0.5,  # ê°•í™” (Overfitting í•´ê²°)\n",
    "    'LABEL_SMOOTHING': 0.1,  # ì¶”ê°€ (Regularization)\n",
    "    \n",
    "    # ğŸ”¥ OCR ì„¤ì •\n",
    "    'USE_OCR': True,\n",
    "    'TEXT_EMB_DIM': 128,  # í…ìŠ¤íŠ¸ ì„ë² ë”© ì°¨ì›\n",
    "    'OCR_HEIGHT_RATIO': 0.25,  # ìƒë‹¨ 25% (ì œëª© ì˜ì—­)\n",
    "    'OCR_MAX_LENGTH': 100,  # OCR í…ìŠ¤íŠ¸ ìµœëŒ€ ê¸¸ì´\n",
    "    \n",
    "    # K-Fold (ì¤‘ìš”!)\n",
    "    'N_FOLDS': 5,  # ğŸ”¥ 5-Fold Cross Validation!\n",
    "    \n",
    "    # ê²½ë¡œ\n",
    "    'BASE_DIR': '/home/realtheai/cv_competetion',\n",
    "    'TRAIN_CSV': '/home/realtheai/cv_competetion/data/train.csv',\n",
    "    'SAMPLE_SUBMISSION_CSV': '/home/realtheai/cv_competetion/data/sample_submission.csv',\n",
    "    'TRAIN_IMG_DIR': '/home/realtheai/cv_competetion/data/train',\n",
    "    'TEST_IMG_DIR': '/home/realtheai/cv_competetion/data/test',\n",
    "    \n",
    "    # ë””ë°”ì´ìŠ¤\n",
    "    'DEVICE': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š Configuration (08_Best_Practice)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ëª¨ë¸: {CFG['MODEL_NAME']}\")\n",
    "print(f\"IMG_SIZE: {CFG['IMG_SIZE']}\")\n",
    "print(f\"BATCH_SIZE: {CFG['BATCH_SIZE']}\")\n",
    "print(f\"EPOCHS: {CFG['EPOCHS']} (Foldë‹¹)\")\n",
    "print(f\"K-Folds: {CFG['N_FOLDS']}\")\n",
    "print(f\"Learning Rate: {CFG['LR']}\")\n",
    "print(f\"Weight Decay: {CFG['WEIGHT_DECAY']}\")\n",
    "print(f\"Dropout: {CFG['DROPOUT']}\")\n",
    "print(f\"Label Smoothing: {CFG['LABEL_SMOOTHING']}\")\n",
    "print(f\"Device: {CFG['DEVICE']}\")\n",
    "print(\"=\"*60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 OCR ì´ˆê¸°í™” ë° í…ìŠ¤íŠ¸ ì²˜ë¦¬ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¥ PaddleOCR ì´ˆê¸°í™” (í•œêµ­ì–´ + GPU ìë™ ê°ì§€)\n",
    "print(\"\\nğŸ“– PaddleOCR ì´ˆê¸°í™” ì¤‘...\")\n",
    "print(\"   (ì²˜ìŒ ì‹¤í–‰ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ 1~2ë¶„ ì†Œìš”)\")\n",
    "\n",
    "# PaddlePaddle GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
    "import paddle\n",
    "print(f\"\\nğŸ” PaddlePaddle ë²„ì „: {paddle.__version__}\")\n",
    "print(f\"   GPU ì»´íŒŒì¼ ì—¬ë¶€: {paddle.device.is_compiled_with_cuda()}\")\n",
    "if paddle.device.is_compiled_with_cuda():\n",
    "    print(f\"   ì‚¬ìš© ê°€ëŠ¥í•œ GPU ìˆ˜: {paddle.device.cuda.device_count()}\")\n",
    "\n",
    "# ë¡œê·¸ ìµœì†Œí™”\n",
    "import logging\n",
    "logging.getLogger('ppocr').setLevel(logging.ERROR)\n",
    "\n",
    "# PaddleOCR ì´ˆê¸°í™” (í•œêµ­ì–´ íŠ¹í™”)\n",
    "# âœ… PaddleOCR 3.0: use_gpu íŒŒë¼ë¯¸í„° ì œê±°ë¨, GPU ìë™ ê°ì§€!\n",
    "ocr = PaddleOCR(\n",
    "    use_angle_cls=True, \n",
    "    lang='korean'\n",
    "    # use_gpu íŒŒë¼ë¯¸í„° ì—†ìŒ â†’ PaddlePaddleì´ ìë™ìœ¼ë¡œ GPU ê°ì§€!\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def extract_text_from_title(image_path, ocr, height_ratio=0.25):\n",
    "\n",
    "    try:\n",
    "        # ì´ë¯¸ì§€ ë¡œë“œ\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_array = np.array(img)\n",
    "        \n",
    "        # ìƒë‹¨ ì˜ì—­ë§Œ crop (ì œëª© ì˜ì—­)\n",
    "        height = img_array.shape[0]\n",
    "        title_region = img_array[:int(height * height_ratio), :]\n",
    "        \n",
    "        # PaddleOCR ìˆ˜í–‰\n",
    "        results = ocr.ocr(title_region, cls=True)\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ì—¬ í•©ì¹˜ê¸°\n",
    "        if results and results[0]:\n",
    "            texts = [line[1][0] for line in results[0]]\n",
    "            combined_text = ' '.join(texts)\n",
    "            return combined_text\n",
    "        \n",
    "        return \"\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        # OCR ì‹¤íŒ¨ì‹œ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def text_to_simple_vector(text, max_length=100):\n",
    "\n",
    "    vector = np.zeros(max_length, dtype=np.float32)\n",
    "    for i, char in enumerate(text[:max_length]):\n",
    "        # ë¬¸ì ì½”ë“œë¥¼ 0~1ë¡œ ì •ê·œí™”\n",
    "        vector[i] = ord(char) / 1000.0\n",
    "    return vector\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinOCRDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, img_dir, ocr, transform=None, is_test=False):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.ocr = ocr\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx]['ID']\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        \n",
    "        # 1. ì´ë¯¸ì§€ ë¡œë“œ\n",
    "        img = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # 2. PaddleOCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "        text = extract_text_from_title(img_path, self.ocr, CFG['OCR_HEIGHT_RATIO'])\n",
    "        ocr_vector = text_to_simple_vector(text, CFG['OCR_MAX_LENGTH'])\n",
    "        ocr_tensor = torch.FloatTensor(ocr_vector)\n",
    "        \n",
    "        # 3. ì´ë¯¸ì§€ augmentation\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        \n",
    "        if self.is_test:\n",
    "            return img, ocr_tensor\n",
    "        \n",
    "        target = self.df.iloc[idx]['target']\n",
    "        return img, ocr_tensor, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Augmentation ì •ì˜ (EDA ê²°ê³¼ ë°˜ì˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05_EDA ê¸°ë°˜ Strong Augmentation\n",
    "trn_transform = A.Compose([\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    \n",
    "    # ğŸ”¥ 05_EDA í•µì‹¬ ë°œê²¬: TestëŠ” ë” íë¦¿í•¨! â†’ Blur ê°•í™”\n",
    "    A.GaussianBlur(blur_limit=(3, 9), p=0.7),  # ê°•í•˜ê²Œ!\n",
    "    A.MotionBlur(blur_limit=7, p=0.4),\n",
    "    \n",
    "    # í’ˆì§ˆ ì €í•˜ ì‹œë®¬ë ˆì´ì…˜ (Test ë°ì´í„° íŠ¹ì§•)\n",
    "    A.ImageCompression(quality_lower=60, p=0.4),\n",
    "    A.Downscale(scale_min=0.7, scale_limit=0.95, p=0.3),\n",
    "    A.GaussNoise(var_limit=(10, 50), p=0.4),\n",
    "    \n",
    "    # ê¸°ë³¸ Augmentation\n",
    "    A.Rotate(limit=3, p=0.3),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=3, p=0.3),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.2, p=0.5),\n",
    "    \n",
    "    # ì •ê·œí™”\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "tst_transform = A.Compose([\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ëª¨ë¸ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¥ Swin Transformer + PaddleOCR Hybrid ëª¨ë¸\n",
    "class SwinOCRClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Swin Transformer + PaddleOCR Hybrid Model\n",
    "    \n",
    "    êµ¬ì¡°:\n",
    "    [OCR Vector] â†’ [Linear] â†’ [ReLU] â†’ [128-dim]\n",
    "                                                    â†’ [Concat] â†’ [FC] â†’ [17 classes]\n",
    "    [Image]      â†’ [Swin Transformer] â†’ [1024-dim]\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name='swin_base_patch4_window7_224',\n",
    "        num_classes=17,\n",
    "        ocr_dim=100,\n",
    "        dropout=0.5\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. Swin Transformer (Backbone)\n",
    "        self.backbone = timm.create_model(model_name, pretrained=True)\n",
    "        \n",
    "        # Swinì˜ ì¶œë ¥ ì°¨ì› í™•ì¸ ë° head ì œê±°\n",
    "        if hasattr(self.backbone, 'head'):\n",
    "            in_features = self.backbone.head.in_features\n",
    "            self.backbone.head = nn.Identity()\n",
    "        elif hasattr(self.backbone, 'fc'):\n",
    "            in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "        else:\n",
    "            in_features = 1024  # Swin-Base ê¸°ë³¸ê°’\n",
    "        \n",
    "        # 2. OCR Feature Encoder\n",
    "        self.ocr_encoder = nn.Sequential(\n",
    "            nn.Linear(ocr_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 3. Feature Fusion + Classifier\n",
    "        fusion_dim = in_features + 128\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(fusion_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, img, ocr_vec):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img: [B, 3, 224, 224]\n",
    "            ocr_vec: [B, 100]\n",
    "        \n",
    "        Returns:\n",
    "            logits: [B, 17]\n",
    "        \"\"\"\n",
    "        # 1. Image features (Swin Transformer)\n",
    "        img_feat = self.backbone(img)\n",
    "        \n",
    "        # 2. OCR features\n",
    "        ocr_feat = self.ocr_encoder(ocr_vec)\n",
    "        \n",
    "        # 3. Feature Fusion (Concatenation)\n",
    "        fused_feat = torch.cat([img_feat, ocr_feat], dim=1)\n",
    "        \n",
    "        # 4. Classification\n",
    "        output = self.classifier(fused_feat)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë“œ\n",
    "train_df = pd.read_csv(CFG['TRAIN_CSV'])\n",
    "test_df = pd.read_csv(CFG['SAMPLE_SUBMISSION_CSV'])\n",
    "meta_df = pd.read_csv(f\"{CFG['BASE_DIR']}/data/meta.csv\")\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ\")\n",
    "print(f\"   - Train: {len(train_df)}ê°œ\")\n",
    "print(f\"   - Test: {len(test_df)}ê°œ\")\n",
    "print(f\"   - í´ë˜ìŠ¤: {CFG['NUM_CLASSES']}ê°œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. í•™ìŠµ í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion, scheduler, device):\n",
    "    \"\"\"1 Epoch í•™ìŠµ\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Training\")\n",
    "    for imgs, ocr_vecs, targets in pbar:\n",
    "        imgs = imgs.to(device)\n",
    "        ocr_vecs = ocr_vecs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs, ocr_vecs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    \"\"\"Validation\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, ocr_vecs, targets in tqdm(loader, desc=\"Validation\"):\n",
    "            imgs = imgs.to(device)\n",
    "            ocr_vecs = ocr_vecs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(imgs, ocr_vecs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            preds = outputs.argmax(dim=1)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    return avg_loss, accuracy, f1, all_preds, all_labels\n",
    "\n",
    "print(\"âœ… í•™ìŠµ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¥ Swin Transformer + PaddleOCR Hybrid ëª¨ë¸\n",
    "class SwinOCRClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Swin Transformer + PaddleOCR Hybrid Model\n",
    "    \n",
    "    êµ¬ì¡°:\n",
    "    [OCR Vector] â†’ [Linear] â†’ [ReLU] â†’ [128-dim]\n",
    "                                                    â†’ [Concat] â†’ [FC] â†’ [17 classes]\n",
    "    [Image]      â†’ [Swin Transformer] â†’ [1024-dim]\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name='swin_base_patch4_window7_224',\n",
    "        num_classes=17,\n",
    "        ocr_dim=100,\n",
    "        dropout=0.5\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. Swin Transformer (Backbone) - forward_features ì‚¬ìš©\n",
    "        self.backbone = timm.create_model(model_name, pretrained=True, num_classes=0)\n",
    "        \n",
    "        # ğŸ”¥ num_classes=0 ìœ¼ë¡œ ì„¤ì •í•˜ë©´ head ì—†ì´ featuresë§Œ ë°˜í™˜\n",
    "        in_features = self.backbone.num_features\n",
    "        \n",
    "        print(f\"âœ… Swin Transformer Feature ì°¨ì›: {in_features}\")\n",
    "        \n",
    "        # 2. OCR Feature Encoder\n",
    "        self.ocr_encoder = nn.Sequential(\n",
    "            nn.Linear(ocr_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 3. Feature Fusion + Classifier\n",
    "        fusion_dim = in_features + 128\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(fusion_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Classifier Input ì°¨ì›: {fusion_dim} (Image {in_features} + OCR 128)\")\n",
    "        \n",
    "        self._first_forward = True  # ë””ë²„ê¹…ìš©\n",
    "    \n",
    "    def forward(self, img, ocr_vec):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img: [B, 3, 224, 224]\n",
    "            ocr_vec: [B, 100]\n",
    "        \n",
    "        Returns:\n",
    "            logits: [B, 17]\n",
    "        \"\"\"\n",
    "        # 1. Image features (Swin Transformer)\n",
    "        # num_classes=0 ì„¤ì •ìœ¼ë¡œ ìë™ìœ¼ë¡œ [B, num_features] ë°˜í™˜\n",
    "        img_feat = self.backbone(img)\n",
    "        \n",
    "        # ğŸ”¥ ë””ë²„ê¹…: ì²« forwardì—ì„œ shape í™•ì¸\n",
    "        if self._first_forward:\n",
    "            print(f\"ğŸ” Debug - img_feat shape: {img_feat.shape}\")\n",
    "            self._first_forward = False\n",
    "        \n",
    "        # 2. OCR features\n",
    "        ocr_feat = self.ocr_encoder(ocr_vec)\n",
    "        \n",
    "        # 3. Feature Fusion (Concatenation)\n",
    "        fused_feat = torch.cat([img_feat, ocr_feat], dim=1)\n",
    "        \n",
    "        # 4. Classification\n",
    "        output = self.classifier(fused_feat)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Split\n",
    "skf = StratifiedKFold(n_splits=CFG['N_FOLDS'], shuffle=True, random_state=SEED)\n",
    "\n",
    "# Foldë³„ ê²°ê³¼ ì €ì¥\n",
    "fold_results = []\n",
    "oof_preds = np.zeros(len(train_df))\n",
    "test_preds = np.zeros((len(test_df), CFG['N_FOLDS']))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸš€ 5-Fold Cross Validation ì‹œì‘!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"ì´ ì˜ˆìƒ ì‹œê°„: ì•½ 25ì‹œê°„ (Foldë‹¹ 5ì‹œê°„)\\n\")\n",
    "\n",
    "# K-Fold í•™ìŠµ\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸ“ Fold {fold + 1}/{CFG['N_FOLDS']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Train/Val Split\n",
    "    trn_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"   Train: {len(trn_df)}ê°œ | Val: {len(val_df)}ê°œ\")\n",
    "    \n",
    "    # Dataset\n",
    "    trn_dataset = SwinOCRDataset(trn_df, CFG['TRAIN_IMG_DIR'], ocr, trn_transform)\n",
    "    val_dataset = SwinOCRDataset(val_df, CFG['TRAIN_IMG_DIR'], ocr, tst_transform)\n",
    "    \n",
    "    # DataLoader\n",
    "    trn_loader = DataLoader(\n",
    "        trn_dataset,\n",
    "        batch_size=CFG['BATCH_SIZE'],\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CFG['BATCH_SIZE'],\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Model\n",
    "    model = SwinOCRClassifier(\n",
    "        CFG['MODEL_NAME'],\n",
    "        CFG['NUM_CLASSES'],\n",
    "        CFG['OCR_MAX_LENGTH'],\n",
    "        CFG['DROPOUT']\n",
    "    ).to(CFG['DEVICE'])\n",
    "    \n",
    "    # Loss (Label Smoothing)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=CFG['LABEL_SMOOTHING'])\n",
    "    \n",
    "    # Optimizer & Scheduler\n",
    "    optimizer = AdamW(\n",
    "        model.parameters(),\n",
    "        lr=CFG['LR'],\n",
    "        weight_decay=CFG['WEIGHT_DECAY']\n",
    "    )\n",
    "    \n",
    "    total_steps = len(trn_loader) * CFG['EPOCHS']\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=total_steps, eta_min=1e-6)\n",
    "    \n",
    "    # Training\n",
    "    best_f1 = 0\n",
    "    best_epoch = 0\n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS'] + 1):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Train\n",
    "        train_loss = train_epoch(model, trn_loader, optimizer, criterion, scheduler, CFG['DEVICE'])\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc, val_f1, val_preds_list, val_targets_list = validate(\n",
    "            model, val_loader, criterion, CFG['DEVICE']\n",
    "        )\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        # Best ëª¨ë¸ ì €ì¥\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), f\"{CFG['BASE_DIR']}/fold{fold+1}_best.pth\")\n",
    "            # OOF ì˜ˆì¸¡ ì €ì¥\n",
    "            oof_preds[val_idx] = val_preds_list\n",
    "            print(f\"   âœ… Best ëª¨ë¸ ì €ì¥! (F1: {best_f1:.4f})\")\n",
    "        \n",
    "        print(f\"\\n[Epoch {epoch}/{CFG['EPOCHS']}] {elapsed_time:.1f}s\")\n",
    "        print(f\"   Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"   Val Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f}\")\n",
    "        print(f\"   Best F1: {best_f1:.4f} (Epoch {best_epoch})\")\n",
    "    \n",
    "    # Fold ê²°ê³¼ ì €ì¥\n",
    "    fold_results.append({\n",
    "        'fold': fold + 1,\n",
    "        'best_f1': best_f1,\n",
    "        'best_epoch': best_epoch\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nğŸ‰ Fold {fold + 1} ì™„ë£Œ!\")\n",
    "    print(f\"   Best F1: {best_f1:.4f} (Epoch {best_epoch})\")\n",
    "    \n",
    "    # Test ì˜ˆì¸¡ (Best ëª¨ë¸)\n",
    "    model.load_state_dict(torch.load(f\"{CFG['BASE_DIR']}/fold{fold+1}_best.pth\"))\n",
    "    model.eval()\n",
    "    \n",
    "    test_dataset = SwinOCRDataset(test_df, CFG['TEST_IMG_DIR'], ocr, tst_transform, is_test=True)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=CFG['BATCH_SIZE'],\n",
    "        shuffle=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    fold_test_preds = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, ocr_vecs in tqdm(test_loader, desc=f\"Fold {fold+1} Test Inference\"):\n",
    "            imgs = imgs.to(CFG['DEVICE'])\n",
    "            ocr_vecs = ocr_vecs.to(CFG['DEVICE'])\n",
    "            outputs = model(imgs, ocr_vecs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            fold_test_preds.extend(preds.cpu().numpy())\n",
    "    \n",
    "    test_preds[:, fold] = fold_test_preds\n",
    "    \n",
    "    print(f\"   âœ… Fold {fold + 1} Test ì˜ˆì¸¡ ì™„ë£Œ\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ‰ ëª¨ë“  Fold í•™ìŠµ ì™„ë£Œ!\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold ê²°ê³¼ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Foldë³„ ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\nğŸ“Š Foldë³„ ê²°ê³¼:\")\n",
    "print(\"=\"*60)\n",
    "for result in fold_results:\n",
    "    print(f\"Fold {result['fold']}: F1 = {result['best_f1']:.4f} (Epoch {result['best_epoch']})\")\n",
    "\n",
    "# í‰ê·  F1\n",
    "mean_f1 = np.mean([r['best_f1'] for r in fold_results])\n",
    "std_f1 = np.std([r['best_f1'] for r in fold_results])\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"í‰ê·  F1: {mean_f1:.4f} Â± {std_f1:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# OOF (Out-of-Fold) ì„±ëŠ¥\n",
    "oof_f1 = f1_score(train_df['target'], oof_preds, average='macro')\n",
    "oof_acc = accuracy_score(train_df['target'], oof_preds)\n",
    "\n",
    "print(f\"\\nğŸ¯ OOF (Out-of-Fold) ì„±ëŠ¥:\")\n",
    "print(f\"   Accuracy: {oof_acc:.4f}\")\n",
    "print(f\"   F1 Score: {oof_f1:.4f}\")\n",
    "print(f\"\\nğŸ’¡ OOF ì„±ëŠ¥ì´ ì‹¤ì œ Leaderboardì™€ ë” ê°€ê¹ìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# 5-Fold ì•™ìƒë¸” (ë‹¤ìˆ˜ê²°)\n",
    "final_preds = stats.mode(test_preds, axis=1)[0].flatten().astype(int)\n",
    "\n",
    "# ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "submission = test_df.copy()\n",
    "submission['target'] = final_preds\n",
    "submission.to_csv(f\"{CFG['BASE_DIR']}/submission.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. í•™ìŠµ ê²°ê³¼ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold ê²°ê³¼ ì‹œê°í™”\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# 1. Foldë³„ Best F1 Score ë¹„êµ\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# (1) Foldë³„ Best F1 Score\n",
    "fold_nums = [r['fold'] for r in fold_results]\n",
    "fold_f1s = [r['best_f1'] for r in fold_results]\n",
    "fold_epochs = [r['best_epoch'] for r in fold_results]\n",
    "\n",
    "axes[0, 0].bar(fold_nums, fold_f1s, color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6'])\n",
    "axes[0, 0].axhline(y=np.mean(fold_f1s), color='red', linestyle='--', linewidth=2, \n",
    "                   label=f'Mean: {np.mean(fold_f1s):.4f}')\n",
    "axes[0, 0].set_title('Best F1 Score per Fold', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Fold')\n",
    "axes[0, 0].set_ylabel('F1 Score')\n",
    "axes[0, 0].set_ylim([min(fold_f1s) - 0.05, max(fold_f1s) + 0.05])\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3, axis='y')\n",
    "for i, (f1, epoch) in enumerate(zip(fold_f1s, fold_epochs)):\n",
    "    axes[0, 0].text(fold_nums[i], f1 + 0.01, f'{f1:.4f}\\n(E{epoch})', \n",
    "                    ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# (2) Foldë³„ Best Epoch\n",
    "axes[0, 1].bar(fold_nums, fold_epochs, color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6'])\n",
    "axes[0, 1].axhline(y=np.mean(fold_epochs), color='red', linestyle='--', linewidth=2,\n",
    "                   label=f'Mean: {np.mean(fold_epochs):.1f}')\n",
    "axes[0, 1].set_title('Best Epoch per Fold', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Fold')\n",
    "axes[0, 1].set_ylabel('Epoch')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3, axis='y')\n",
    "for i, epoch in enumerate(fold_epochs):\n",
    "    axes[0, 1].text(fold_nums[i], epoch + 0.3, f'{epoch}', \n",
    "                    ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# (3) F1 Score ë¶„í¬ (Box Plot)\n",
    "axes[1, 0].boxplot([fold_f1s], labels=['All Folds'], widths=0.5)\n",
    "axes[1, 0].scatter([1]*len(fold_f1s), fold_f1s, c=['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6'], \n",
    "                   s=100, alpha=0.6, edgecolors='black', linewidth=1.5)\n",
    "axes[1, 0].set_title('F1 Score Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('F1 Score')\n",
    "axes[1, 0].grid(alpha=0.3, axis='y')\n",
    "axes[1, 0].text(1.3, np.mean(fold_f1s), \n",
    "                f'Mean: {np.mean(fold_f1s):.4f}\\nStd: {np.std(fold_f1s):.4f}\\nOOF: {oof_f1:.4f}',\n",
    "                fontsize=11, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# (4) ì„±ëŠ¥ ìš”ì•½ í…Œì´ë¸”\n",
    "axes[1, 1].axis('off')\n",
    "summary_data = [\n",
    "    ['Metric', 'Value'],\n",
    "    ['â”€' * 20, 'â”€' * 20],\n",
    "    ['Mean F1 (Folds)', f'{np.mean(fold_f1s):.4f}'],\n",
    "    ['Std F1 (Folds)', f'{np.std(fold_f1s):.4f}'],\n",
    "    ['Min F1', f'{min(fold_f1s):.4f}'],\n",
    "    ['Max F1', f'{max(fold_f1s):.4f}'],\n",
    "    ['â”€' * 20, 'â”€' * 20],\n",
    "    ['OOF F1 Score', f'{oof_f1:.4f}'],\n",
    "    ['OOF Accuracy', f'{oof_acc:.4f}'],\n",
    "    ['â”€' * 20, 'â”€' * 20],\n",
    "    ['Best Fold', f'Fold {fold_nums[np.argmax(fold_f1s)]}'],\n",
    "    ['Worst Fold', f'Fold {fold_nums[np.argmin(fold_f1s)]}'],\n",
    "    ['Mean Best Epoch', f'{np.mean(fold_epochs):.1f}'],\n",
    "]\n",
    "\n",
    "table = axes[1, 1].table(cellText=summary_data, cellLoc='left', loc='center',\n",
    "                         colWidths=[0.6, 0.4])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1, 2.5)\n",
    "\n",
    "# í—¤ë” ìŠ¤íƒ€ì¼\n",
    "for i in range(2):\n",
    "    table[(0, i)].set_facecolor('#3498db')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# OOF í–‰ ê°•ì¡°\n",
    "for i in range(2):\n",
    "    table[(7, i)].set_facecolor('#2ecc71')\n",
    "    table[(7, i)].set_text_props(weight='bold')\n",
    "    table[(8, i)].set_facecolor('#2ecc71')\n",
    "    table[(8, i)].set_text_props(weight='bold')\n",
    "\n",
    "axes[1, 1].set_title('Performance Summary', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CFG['BASE_DIR']}/kfold_results.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nğŸ’¾ K-Fold ê²°ê³¼ ì‹œê°í™” ì €ì¥: {CFG['BASE_DIR']}/kfold_results.png\")\n",
    "print(\"\\nğŸ“Š ì‹œê°í™” ë‚´ìš©:\")\n",
    "print(\"   1. Foldë³„ Best F1 Score ë¹„êµ\")\n",
    "print(\"   2. Foldë³„ Best Epoch\")\n",
    "print(\"   3. F1 Score ë¶„í¬ (Box Plot)\")\n",
    "print(\"   4. ì„±ëŠ¥ ìš”ì•½ í…Œì´ë¸” (OOF í¬í•¨)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. í‹€ë¦° ì´ë¯¸ì§€ ë¶„ì„ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” OOF (Out-of-Fold) í‹€ë¦° ì˜ˆì¸¡ ë¶„ì„\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ” í‹€ë¦° ì˜ˆì¸¡ ë¶„ì„ (OOF)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# OOF ì˜ˆì¸¡ê³¼ ì‹¤ì œ ë ˆì´ë¸” ë¹„êµ (ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜)\n",
    "oof_preds_int = oof_preds.astype(int)\n",
    "actual_labels = train_df['target'].values.astype(int)\n",
    "\n",
    "wrong_mask = (oof_preds_int != actual_labels)\n",
    "wrong_df = train_df[wrong_mask].copy()\n",
    "wrong_df['predicted'] = oof_preds_int[wrong_mask]\n",
    "wrong_df['actual'] = actual_labels[wrong_mask]\n",
    "\n",
    "print(f\"\\nğŸ“Š ì „ì²´ í‹€ë¦° ì˜ˆì¸¡: {len(wrong_df)}ê°œ / {len(train_df)}ê°œ (ì •í™•ë„: {(1 - len(wrong_df)/len(train_df))*100:.2f}%)\")\n",
    "\n",
    "# í´ë˜ìŠ¤ë³„ ì˜¤ë‹µ ë¶„ì„\n",
    "print(f\"\\nğŸ“ˆ í´ë˜ìŠ¤ë³„ ì˜¤ë‹µ ê°œìˆ˜:\")\n",
    "wrong_by_class = wrong_df.groupby('actual').size().sort_values(ascending=False)\n",
    "for class_id, count in wrong_by_class.items():\n",
    "    class_id = int(class_id)\n",
    "    class_name = meta_df[meta_df['target'] == class_id]['class_name'].values[0]\n",
    "    total_in_class = (train_df['target'] == class_id).sum()\n",
    "    error_rate = (count / total_in_class) * 100\n",
    "    print(f\"   Class {class_id:2d} ({class_name[:25]:25s}): {count:2d}/{total_in_class:3d} ({error_rate:5.1f}% ì˜¤ë‹µ)\")\n",
    "\n",
    "# ê°€ì¥ ë§ì´ í˜¼ë™ë˜ëŠ” í´ë˜ìŠ¤ ìŒ\n",
    "print(f\"\\nğŸ”¥ ê°€ì¥ ë§ì´ í˜¼ë™ë˜ëŠ” í´ë˜ìŠ¤ ìŒ (Top 10):\")\n",
    "confusion_pairs = wrong_df.groupby(['actual', 'predicted']).size().sort_values(ascending=False).head(10)\n",
    "for idx, ((actual, pred), count) in enumerate(confusion_pairs.items(), 1):\n",
    "    actual = int(actual)\n",
    "    pred = int(pred)\n",
    "    actual_name = meta_df[meta_df['target'] == actual]['class_name'].values[0]\n",
    "    pred_name = meta_df[meta_df['target'] == pred]['class_name'].values[0]\n",
    "    print(f\"   {idx:2d}. Class {actual:2d} ({actual_name[:20]:20s}) â†’ Class {pred:2d} ({pred_name[:20]:20s}): {count}ê°œ\")\n",
    "\n",
    "# í‹€ë¦° ì´ë¯¸ì§€ ì‹œê°í™” (ìµœëŒ€ 12ê°œ)\n",
    "print(f\"\\nğŸ–¼ï¸ í‹€ë¦° ì˜ˆì¸¡ ìƒ˜í”Œ ì‹œê°í™” (ìµœëŒ€ 12ê°œ)\")\n",
    "n_samples = min(12, len(wrong_df))\n",
    "sample_indices = np.random.choice(len(wrong_df), n_samples, replace=False)\n",
    "samples = wrong_df.iloc[sample_indices]\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (ax, (_, row)) in enumerate(zip(axes, samples.iterrows())):\n",
    "    img_path = os.path.join(CFG['TRAIN_IMG_DIR'], row['ID'])\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    \n",
    "    actual = int(row['actual'])\n",
    "    predicted = int(row['predicted'])\n",
    "    actual_name = meta_df[meta_df['target'] == actual]['class_name'].values[0]\n",
    "    pred_name = meta_df[meta_df['target'] == predicted]['class_name'].values[0]\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"ì‹¤ì œ: {actual} ({actual_name[:15]})\\nì˜ˆì¸¡: {predicted} ({pred_name[:15]})\",\n",
    "                 fontsize=9, color='red', fontweight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CFG['BASE_DIR']}/wrong_predictions.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nğŸ’¾ í‹€ë¦° ì˜ˆì¸¡ ì‹œê°í™” ì €ì¥: {CFG['BASE_DIR']}/wrong_predictions.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” OOF Confusion Matrix ì‹œê°í™”\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“Š OOF Confusion Matrix\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# OOF ì˜ˆì¸¡ìœ¼ë¡œ Confusion Matrix ìƒì„±\n",
    "oof_preds_int = oof_preds.astype(int)\n",
    "actual_labels = train_df['target'].values.astype(int)\n",
    "cm = confusion_matrix(actual_labels, oof_preds_int)\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig, ax = plt.subplots(figsize=(16, 14))\n",
    "im = ax.imshow(cm, cmap='Blues', interpolation='nearest')\n",
    "ax.set_title('Confusion Matrix (OOF - 5-Fold)', fontsize=18, fontweight='bold', pad=20)\n",
    "\n",
    "# ì»¬ëŸ¬ë°”\n",
    "cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Count', fontsize=12)\n",
    "\n",
    "# ì¶• ë ˆì´ë¸” (í´ë˜ìŠ¤ ì´ë¦„)\n",
    "tick_labels = []\n",
    "for i in range(CFG['NUM_CLASSES']):\n",
    "    class_name = meta_df[meta_df['target']==i]['class_name'].values[0]\n",
    "    # í´ë˜ìŠ¤ ì´ë¦„ ì¤„ë°”ê¿ˆ ì²˜ë¦¬ (ê¸´ ì´ë¦„ ëŒ€ì‘)\n",
    "    if len(class_name) > 15:\n",
    "        class_name = class_name[:12] + '...'\n",
    "    tick_labels.append(f\"{i}\\n{class_name}\")\n",
    "\n",
    "ax.set_xticks(range(CFG['NUM_CLASSES']))\n",
    "ax.set_yticks(range(CFG['NUM_CLASSES']))\n",
    "ax.set_xticklabels(tick_labels, rotation=45, ha='right', fontsize=9)\n",
    "ax.set_yticklabels(tick_labels, fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Predicted Label', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('True Label', fontsize=14, fontweight='bold')\n",
    "\n",
    "# ê° ì…€ì— ìˆ«ì í‘œì‹œ\n",
    "threshold = cm.max() / 2\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        # ëŒ€ê°ì„ (ì •ë‹µ)ì€ ë…¹ìƒ‰ í…ìŠ¤íŠ¸, ì˜¤ë‹µì€ ê¸°ë³¸ ìƒ‰ìƒ\n",
    "        if i == j:\n",
    "            color = 'darkgreen' if cm[i, j] > threshold else 'green'\n",
    "            weight = 'bold'\n",
    "        else:\n",
    "            color = 'white' if cm[i, j] > threshold else 'black'\n",
    "            weight = 'normal'\n",
    "        \n",
    "        # 0ì€ í‘œì‹œí•˜ì§€ ì•ŠìŒ (ê¹”ë”í•˜ê²Œ)\n",
    "        if cm[i, j] > 0:\n",
    "            ax.text(j, i, str(cm[i, j]), \n",
    "                   ha='center', va='center',\n",
    "                   color=color, fontsize=9, fontweight=weight)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CFG['BASE_DIR']}/confusion_matrix.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nğŸ’¾ Confusion Matrix ì €ì¥: {CFG['BASE_DIR']}/confusion_matrix.png\")\n",
    "\n",
    "# í†µê³„ ì •ë³´\n",
    "print(f\"\\nğŸ“Š Confusion Matrix í†µê³„:\")\n",
    "print(f\"   ì´ ìƒ˜í”Œ: {cm.sum():.0f}ê°œ\")\n",
    "print(f\"   ì •ë‹µ (ëŒ€ê°ì„ ): {np.trace(cm):.0f}ê°œ\")\n",
    "print(f\"   ì˜¤ë‹µ (ë¹„ëŒ€ê°ì„ ): {cm.sum() - np.trace(cm):.0f}ê°œ\")\n",
    "print(f\"   ì •í™•ë„: {np.trace(cm) / cm.sum() * 100:.2f}%\")\n",
    "\n",
    "# í´ë˜ìŠ¤ë³„ ì •í™•ë„ (Recall)\n",
    "print(f\"\\nğŸ“ˆ í´ë˜ìŠ¤ë³„ Recall (ì •ë‹µë¥ ):\")\n",
    "for i in range(CFG['NUM_CLASSES']):\n",
    "    class_name = meta_df[meta_df['target']==i]['class_name'].values[0]\n",
    "    total = cm[i, :].sum()\n",
    "    correct = cm[i, i]\n",
    "    recall = (correct / total * 100) if total > 0 else 0\n",
    "    print(f\"   Class {i:2d} ({class_name[:25]:25s}): {correct:3.0f}/{total:3.0f} ({recall:5.1f}%)\")\n",
    "\n",
    "# ê°€ì¥ ë§ì´ í˜¼ë™ë˜ëŠ” ìŒ ì°¾ê¸°\n",
    "print(f\"\\nğŸ”¥ ê°€ì¥ ë§ì´ í˜¼ë™ëœ í´ë˜ìŠ¤ ìŒ (ë¹„ëŒ€ê°ì„  Top 5):\")\n",
    "confusion_list = []\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        if i != j and cm[i, j] > 0:  # ëŒ€ê°ì„  ì œì™¸\n",
    "            confusion_list.append((i, j, cm[i, j]))\n",
    "\n",
    "# í˜¼ë™ ê°œìˆ˜ë¡œ ì •ë ¬\n",
    "confusion_list.sort(key=lambda x: x[2], reverse=True)\n",
    "for idx, (true_class, pred_class, count) in enumerate(confusion_list[:5], 1):\n",
    "    true_name = meta_df[meta_df['target']==true_class]['class_name'].values[0]\n",
    "    pred_name = meta_df[meta_df['target']==pred_class]['class_name'].values[0]\n",
    "    print(f\"   {idx}. Class {true_class:2d} ({true_name[:20]:20s}) â†’ Class {pred_class:2d} ({pred_name[:20]:20s}): {count:.0f}ê°œ\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Confusion Matrix í•´ì„:\")\n",
    "print(\"   âœ… ëŒ€ê°ì„  (ë…¹ìƒ‰): ì •í™•í•˜ê²Œ ì˜ˆì¸¡í•œ ê°œìˆ˜\")\n",
    "print(\"   âŒ ë¹„ëŒ€ê°ì„ : ì˜ëª» ì˜ˆì¸¡í•œ ê°œìˆ˜\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
