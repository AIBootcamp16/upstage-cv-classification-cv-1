{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install timm albumentations -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ì‹œë“œ ê³ ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œë“œ ê³ ì •\n",
    "SEED = 42\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyperparameters (EDA ê²°ê³¼ ë°˜ì˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== í•˜ì´í¼íŒŒë¼ë¯¸í„° (EDA ê²°ê³¼ ë°˜ì˜) ========== #\n",
    "CFG = {\n",
    "    # ë°ì´í„°\n",
    "    'IMG_SIZE': 224,           # EDA: í‰ê·  484x551 â†’ 224ë¡œ resize\n",
    "    'BATCH_SIZE': 32,\n",
    "    'NUM_CLASSES': 17,\n",
    "    \n",
    "    # í•™ìŠµ\n",
    "    'EPOCHS': 20,              # ë” ê¸´ í•™ìŠµ\n",
    "    'LR': 1e-4,\n",
    "    'WEIGHT_DECAY': 1e-5,      # ì •ê·œí™” ì¶”ê°€\n",
    "    \n",
    "    # ëª¨ë¸\n",
    "    'MODEL_NAME': 'resnet50',  # 'efficientnet_b3', 'convnext_base'\n",
    "    \n",
    "    # K-Fold\n",
    "    'N_FOLDS': 1,\n",
    "    'FOLD_TO_RUN': 0,\n",
    "    \n",
    "    # ê²½ë¡œ (EDA íŒŒì¼ê³¼ ë™ì¼)\n",
    "    'BASE_DIR': '/home/realtheai/cv_competetion',\n",
    "    'TRAIN_CSV': '/home/realtheai/cv_competetion/data/train.csv',\n",
    "    'SAMPLE_SUBMISSION_CSV': '/home/realtheai/cv_competetion/data/sample_submission.csv',\n",
    "    'TRAIN_IMG_DIR': '/home/realtheai/cv_competetion/data/train',\n",
    "    'TEST_IMG_DIR': '/home/realtheai/cv_competetion/data/test',\n",
    "    \n",
    "    # ë””ë°”ì´ìŠ¤\n",
    "    'DEVICE': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    \n",
    "    # Augmentation ê°•ë„ (EDA ê²°ê³¼: Testì— ë§ì€ ë…¸ì´ì¦ˆ)\n",
    "    'AUG_STRENGTH': 0.7,       # 0.5 â†’ 0.7 (ê°•í™”!)\n",
    "    \n",
    "    # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì‚¬ìš© ì—¬ë¶€ (EDA ê²°ê³¼: 2.2:1 ë¶ˆê· í˜•)\n",
    "    'USE_CLASS_WEIGHTS': True,\n",
    "}\n",
    "\n",
    "print(\"\\n=== Configuration (EDA ê²°ê³¼ ë°˜ì˜) ===\")\n",
    "for k, v in CFG.items():\n",
    "    print(f\"{k:25s}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img_path = os.path.join(self.path, name)\n",
    "        \n",
    "        # RGBë¡œ ë³€í™˜ (ì¼ë¶€ grayscale ì´ë¯¸ì§€ ëŒ€ì‘)\n",
    "        img = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Augmentation ì •ì˜ (EDA ê²°ê³¼ ë°˜ì˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms(img_size=224, aug_strength=0.7):\n",
    "\n",
    "    return A.Compose([\n",
    "        # í¬ê¸° ì¡°ì •\n",
    "        A.Resize(img_size, img_size),\n",
    "        \n",
    "        # ========== EDA ë°œê²¬: ê¸°ìš¸ì–´ì§ ëŒ€ì‘ ========== #\n",
    "        A.Perspective(scale=(0.05, 0.1), p=aug_strength * 0.5),  # ì›ê·¼ ì™œê³¡\n",
    "        A.Rotate(limit=15, p=aug_strength),                      # íšŒì „ (10â†’15ë„)\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0.1, \n",
    "            scale_limit=0.15, \n",
    "            rotate_limit=15, \n",
    "            p=aug_strength\n",
    "        ),\n",
    "        \n",
    "        # ========== EDA ë°œê²¬: êµ¬ê²¨ì§ ëŒ€ì‘ ========== #\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.3, p=aug_strength * 0.5),\n",
    "        A.OpticalDistortion(distort_limit=0.3, shift_limit=0.3, p=aug_strength * 0.3),\n",
    "        \n",
    "        # ========== EDA ë°œê²¬: ë°ê¸° ì°¨ì´ ëŒ€ì‘ (ì¤‘ìš”!) ========== #\n",
    "        A.RandomBrightnessContrast(\n",
    "            brightness_limit=0.3,   # 0.2 â†’ 0.3 ê°•í™”!\n",
    "            contrast_limit=0.3,     # 0.2 â†’ 0.3 ê°•í™”!\n",
    "            p=aug_strength\n",
    "        ),\n",
    "        A.RandomGamma(gamma_limit=(70, 130), p=aug_strength),  # (80,120) â†’ (70,130)\n",
    "        \n",
    "        # ========== EDA ë°œê²¬: ë¹› ë°˜ì‚¬/ë²ˆì§ ëŒ€ì‘ ========== #\n",
    "        A.RandomShadow(\n",
    "            shadow_roi=(0, 0.5, 1, 1), \n",
    "            num_shadows_limit=(1, 3),  # 1-2 â†’ 1-3 ì¦ê°€\n",
    "            p=aug_strength * 0.5\n",
    "        ),\n",
    "        A.RandomSunFlare(flare_roi=(0, 0, 1, 0.5), p=aug_strength * 0.2),  # ë¹›ë²ˆì§ ì¶”ê°€\n",
    "        \n",
    "        # ========== ë…¸ì´ì¦ˆ ì¶”ê°€ ========== #\n",
    "        A.OneOf([\n",
    "            A.GaussNoise(var_limit=(10, 50)),\n",
    "            A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5)),\n",
    "        ], p=aug_strength * 0.5),\n",
    "        \n",
    "        A.OneOf([\n",
    "            A.GaussianBlur(blur_limit=(3, 7)),      # (3,5) â†’ (3,7)\n",
    "            A.MotionBlur(blur_limit=(3, 7)),\n",
    "        ], p=aug_strength * 0.5),\n",
    "        \n",
    "        # ========== EDA ë°œê²¬: ê°€ë¦¼ ëŒ€ì‘ ========== #\n",
    "        A.CoarseDropout(\n",
    "            max_holes=12,          # 8 â†’ 12 ì¦ê°€\n",
    "            max_height=32, \n",
    "            max_width=32, \n",
    "            p=aug_strength * 0.5\n",
    "        ),\n",
    "        \n",
    "        # ìƒ‰ìƒ ë³€í™”\n",
    "        A.HueSaturationValue(\n",
    "            hue_shift_limit=10, \n",
    "            sat_shift_limit=20, \n",
    "            val_shift_limit=10, \n",
    "            p=aug_strength * 0.3\n",
    "        ),\n",
    "        \n",
    "        # ì •ê·œí™” ë° í…ì„œ ë³€í™˜\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "def get_valid_transforms(img_size=224):\n",
    "    \"\"\"Validationìš© transform (augmentation ì—†ìŒ)\"\"\"\n",
    "    return A.Compose([\n",
    "        A.Resize(img_size, img_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ëª¨ë¸ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name='resnet50', num_classes=17, pretrained=True):\n",
    "    \"\"\"timmì„ ì‚¬ìš©í•œ ëª¨ë¸ ìƒì„±\"\"\"\n",
    "    model = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=pretrained,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸\n",
    "model = create_model(\n",
    "    model_name=CFG['MODEL_NAME'],\n",
    "    num_classes=CFG['NUM_CLASSES']\n",
    ")\n",
    "model = model.to(CFG['DEVICE'])\n",
    "\n",
    "print(f\"\\nâœ… ëª¨ë¸ ìƒì„± ì™„ë£Œ: {CFG['MODEL_NAME']}\")\n",
    "print(f\"   - ì´ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"   - í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. í•™ìŠµ/ê²€ì¦ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í•™ìŠµ/ê²€ì¦ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "def train_one_epoch(loader, model, optimizer, loss_fn, device, scheduler=None):\n",
    "    \"\"\"1 epoch í•™ìŠµ\"\"\"\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader, desc='Training')\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "        \n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    avg_loss = train_loss / len(loader)\n",
    "    acc = accuracy_score(targets_list, preds_list)\n",
    "    f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "    \n",
    "    return avg_loss, acc, f1\n",
    "\n",
    "\n",
    "def validate(loader, model, loss_fn, device):\n",
    "    \"\"\"ê²€ì¦\"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc='Validation')\n",
    "        for image, targets in pbar:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(1).cpu().numpy())\n",
    "            targets_list.extend(targets.cpu().numpy())\n",
    "            \n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    avg_loss = val_loss / len(loader)\n",
    "    acc = accuracy_score(targets_list, preds_list)\n",
    "    f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "    \n",
    "    return avg_loss, acc, f1, preds_list, targets_list\n",
    "\n",
    "print(\"âœ… í•™ìŠµ/ê²€ì¦ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. í‹€ë¦° ì´ë¯¸ì§€ ë¶„ì„ í•¨ìˆ˜ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_wrong_predictions(val_df, preds_list, targets_list, img_dir, meta_df=None, save_path=None):\n",
    "\n",
    "    # í‹€ë¦° ì¸ë±ìŠ¤ ì°¾ê¸°\n",
    "    wrong_indices = [i for i, (pred, target) in enumerate(zip(preds_list, targets_list)) if pred != target]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ“Š ê²€ì¦ ê²°ê³¼ ë¶„ì„\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"   ì „ì²´: {len(preds_list)}ê°œ\")\n",
    "    print(f\"   ì •ë‹µ: {len(preds_list) - len(wrong_indices)}ê°œ\")\n",
    "    print(f\"   ì˜¤ë‹µ: {len(wrong_indices)}ê°œ ({len(wrong_indices)/len(preds_list)*100:.1f}%)\")\n",
    "    print(f\"   ì •í™•ë„: {(len(preds_list) - len(wrong_indices))/len(preds_list)*100:.1f}%\")\n",
    "    \n",
    "    if len(wrong_indices) == 0:\n",
    "        print(\"\\nğŸ‰ ëª¨ë“  ì˜ˆì¸¡ì´ ì •í™•í•©ë‹ˆë‹¤!\")\n",
    "        return\n",
    "    \n",
    "    # í´ë˜ìŠ¤ë³„ ì˜¤ë¥˜ ë¶„ì„\n",
    "    wrong_by_true_class = {}\n",
    "    for idx in wrong_indices:\n",
    "        true_class = targets_list[idx]\n",
    "        pred_class = preds_list[idx]\n",
    "        if true_class not in wrong_by_true_class:\n",
    "            wrong_by_true_class[true_class] = []\n",
    "        wrong_by_true_class[true_class].append((idx, pred_class))\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ í´ë˜ìŠ¤ë³„ ì˜¤ë‹µ ë¶„ì„:\")\n",
    "    for class_id in sorted(wrong_by_true_class.keys()):\n",
    "        count = len(wrong_by_true_class[class_id])\n",
    "        if meta_df is not None:\n",
    "            class_name = meta_df[meta_df['target'] == class_id]['class_name'].values[0]\n",
    "            print(f\"   Class {class_id:2d} ({class_name[:20]:20s}): {count:2d}ê°œ ì˜¤ë‹µ\")\n",
    "        else:\n",
    "            print(f\"   Class {class_id:2d}: {count:2d}ê°œ ì˜¤ë‹µ\")\n",
    "    \n",
    "    # í‹€ë¦° ì´ë¯¸ì§€ ìµœëŒ€ 12ê°œ ì‹œê°í™”\n",
    "    if save_path:\n",
    "        n_show = min(12, len(wrong_indices))\n",
    "        fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, idx in enumerate(wrong_indices[:n_show]):\n",
    "            img_name = val_df.iloc[idx]['ID']\n",
    "            img_path = os.path.join(img_dir, img_name)\n",
    "            \n",
    "            if os.path.exists(img_path):\n",
    "                img = Image.open(img_path)\n",
    "                axes[i].imshow(img)\n",
    "                \n",
    "                true_label = f\"True: {targets_list[idx]}\"\n",
    "                pred_label = f\"Pred: {preds_list[idx]}\"\n",
    "                \n",
    "                if meta_df is not None:\n",
    "                    true_class = meta_df[meta_df['target'] == targets_list[idx]]['class_name'].values[0]\n",
    "                    pred_class = meta_df[meta_df['target'] == preds_list[idx]]['class_name'].values[0]\n",
    "                    true_label += f\"\\n({true_class[:15]})\"\n",
    "                    pred_label += f\"\\n({pred_class[:15]})\"\n",
    "                \n",
    "                axes[i].set_title(\n",
    "                    f\"{true_label}\\n{pred_label}\",\n",
    "                    fontsize=9,\n",
    "                    color='red',\n",
    "                    fontweight='bold'\n",
    "                )\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        # ë¹ˆ subplot ìˆ¨ê¸°ê¸°\n",
    "        for i in range(n_show, 12):\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(f\"\\nğŸ’¾ í‹€ë¦° ì´ë¯¸ì§€ ì €ì¥: {save_path}\")\n",
    "    \n",
    "\n",
    "print(\"âœ… ê²°ê³¼ ë¶„ì„ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë“œ\n",
    "train_df = pd.read_csv(CFG['TRAIN_CSV'])\n",
    "test_df = pd.read_csv(CFG['SAMPLE_SUBMISSION_CSV'])\n",
    "meta_df = pd.read_csv(f\"{CFG['BASE_DIR']}/data/meta.csv\")\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ\")\n",
    "print(f\"   - Train: {len(train_df)}ê°œ\")\n",
    "print(f\"   - Test: {len(test_df)}ê°œ\")\n",
    "print(f\"   - í´ë˜ìŠ¤: {len(meta_df)}ê°œ\")\n",
    "\n",
    "# Transform ìƒì„±\n",
    "train_transform = get_train_transforms(\n",
    "    img_size=CFG['IMG_SIZE'],\n",
    "    aug_strength=CFG['AUG_STRENGTH']\n",
    ")\n",
    "valid_transform = get_valid_transforms(img_size=CFG['IMG_SIZE'])\n",
    "\n",
    "print(f\"\\nâœ… Transform ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"   - Augmentation ê°•ë„: {CFG['AUG_STRENGTH']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° (EDA ë°œê²¬: 2.2:1 ë¶ˆê· í˜•)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸\n",
    "class_counts = train_df['target'].value_counts().sort_index()\n",
    "print(\"\\nğŸ“Š í´ë˜ìŠ¤ ë¶„í¬:\")\n",
    "for class_id, count in class_counts.items():\n",
    "    class_name = meta_df[meta_df['target'] == class_id]['class_name'].values[0]\n",
    "    print(f\"   Class {class_id:2d} ({class_name[:25]:25s}): {count:3d}ê°œ\")\n",
    "\n",
    "# ë¶ˆê· í˜• ë¹„ìœ¨ ê³„ì‚°\n",
    "max_count = class_counts.max()\n",
    "min_count = class_counts.min()\n",
    "imbalance_ratio = max_count / min_count\n",
    "\n",
    "print(f\"\\nâš ï¸ í´ë˜ìŠ¤ ë¶ˆê· í˜•:\")\n",
    "print(f\"   ìµœëŒ€: {max_count}ê°œ / ìµœì†Œ: {min_count}ê°œ\")\n",
    "print(f\"   ë¹„ìœ¨: {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "if CFG['USE_CLASS_WEIGHTS']:\n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(train_df['target']),\n",
    "        y=train_df['target']\n",
    "    )\n",
    "    class_weights = torch.FloatTensor(class_weights).to(CFG['DEVICE'])\n",
    "    \n",
    "    print(f\"\\nâœ… í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©:\")\n",
    "    for i, weight in enumerate(class_weights):\n",
    "        print(f\"   Class {i:2d}: {weight:.4f}\")\n",
    "else:\n",
    "    class_weights = None\n",
    "    print(f\"\\nâŒ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ë¯¸ì‚¬ìš©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Train/Validation ë¶„í• "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation ë¶„í•  (80:20, Stratified)\n",
    "train_idx, val_idx = train_test_split(\n",
    "    range(len(train_df)),\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=train_df['target']\n",
    ")\n",
    "\n",
    "# CSV íŒŒì¼ ì„ì‹œ ìƒì„±\n",
    "train_df.iloc[train_idx].to_csv(f\"{CFG['BASE_DIR']}/train_fold.csv\", index=False)\n",
    "train_df.iloc[val_idx].to_csv(f\"{CFG['BASE_DIR']}/val_fold.csv\", index=False)\n",
    "\n",
    "# Dataset ìƒì„±\n",
    "trn_dataset = ImageDataset(f\"{CFG['BASE_DIR']}/train_fold.csv\", CFG['TRAIN_IMG_DIR'], train_transform)\n",
    "val_dataset = ImageDataset(f\"{CFG['BASE_DIR']}/val_fold.csv\", CFG['TRAIN_IMG_DIR'], valid_transform)\n",
    "\n",
    "# DataLoader ìƒì„±\n",
    "trn_loader = DataLoader(\n",
    "    trn_dataset,\n",
    "    batch_size=CFG['BATCH_SIZE'],\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CFG['BATCH_SIZE'],\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"âœ… DataLoader ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"   - Train: {len(trn_loader)} batches ({len(trn_dataset)}ê°œ)\")\n",
    "print(f\"   - Valid: {len(val_loader)} batches ({len(val_dataset)}ê°œ)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. í•™ìŠµ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸, ì˜µí‹°ë§ˆì´ì €, ì†ì‹¤ í•¨ìˆ˜, ìŠ¤ì¼€ì¤„ëŸ¬\n",
    "model = create_model(CFG['MODEL_NAME'], CFG['NUM_CLASSES']).to(CFG['DEVICE'])\n",
    "\n",
    "optimizer = Adam(\n",
    "    model.parameters(), \n",
    "    lr=CFG['LR'],\n",
    "    weight_decay=CFG['WEIGHT_DECAY']\n",
    ")\n",
    "\n",
    "# Weighted Loss (EDA ê²°ê³¼ ë°˜ì˜)\n",
    "if CFG['USE_CLASS_WEIGHTS']:\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    print(\"âœ… Weighted CrossEntropyLoss ì‚¬ìš©\")\n",
    "else:\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    print(\"âœ… CrossEntropyLoss ì‚¬ìš©\")\n",
    "\n",
    "# Cosine Annealing Scheduler\n",
    "scheduler = CosineAnnealingLR(\n",
    "    optimizer, \n",
    "    T_max=CFG['EPOCHS'] * len(trn_loader),\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… í•™ìŠµ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(f\"   - Optimizer: Adam (lr={CFG['LR']}, wd={CFG['WEIGHT_DECAY']})\")\n",
    "print(f\"   - Scheduler: CosineAnnealingLR\")\n",
    "print(f\"   - Loss: {'Weighted ' if CFG['USE_CLASS_WEIGHTS'] else ''}CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. í•™ìŠµ ì‹¤í–‰ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"í•™ìŠµ ì‹œì‘!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_f1 = 0\n",
    "best_epoch = 0\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [], 'train_f1': [],\n",
    "    'val_loss': [], 'val_acc': [], 'val_f1': []\n",
    "}\n",
    "\n",
    "for epoch in range(CFG['EPOCHS']):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Epoch {epoch+1}/{CFG['EPOCHS']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc, train_f1 = train_one_epoch(\n",
    "        trn_loader, model, optimizer, loss_fn, CFG['DEVICE'], scheduler\n",
    "    )\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, val_acc, val_f1, preds, targets = validate(\n",
    "        val_loader, model, loss_fn, CFG['DEVICE']\n",
    "    )\n",
    "    \n",
    "    # History ì €ì¥\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_f1'].append(train_f1)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_f1'].append(val_f1)\n",
    "    \n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print(f\"\\nğŸ“Š Epoch {epoch+1} Results:\")\n",
    "    print(f\"   Train - Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f}\")\n",
    "    print(f\"   Valid - Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f}\")\n",
    "    \n",
    "    # Best ëª¨ë¸ ì €ì¥\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save(model.state_dict(), f\"{CFG['BASE_DIR']}/best_model.pth\")\n",
    "        print(f\"   ğŸ‰ Best model saved! (F1: {best_f1:.4f})\")\n",
    "    \n",
    "    # Early Stopping ì²´í¬ (ê°„ë‹¨ ë²„ì „)\n",
    "    if epoch - best_epoch >= 5:\n",
    "        print(f\"\\nâš ï¸ Early Stopping! (Best epoch: {best_epoch})\")\n",
    "        break\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ğŸ‰ í•™ìŠµ ì™„ë£Œ!\")\n",
    "print(f\"   Best Validation F1: {best_f1:.4f} (Epoch {best_epoch})\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. í•™ìŠµ ê²°ê³¼ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ ê³¡ì„  ê·¸ë¦¬ê¸°\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train', marker='o')\n",
    "axes[0].plot(history['val_loss'], label='Valid', marker='o')\n",
    "axes[0].set_title('Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history['train_acc'], label='Train', marker='o')\n",
    "axes[1].plot(history['val_acc'], label='Valid', marker='o')\n",
    "axes[1].set_title('Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# F1 Score\n",
    "axes[2].plot(history['train_f1'], label='Train', marker='o')\n",
    "axes[2].plot(history['val_f1'], label='Valid', marker='o')\n",
    "axes[2].axhline(y=best_f1, color='r', linestyle='--', label=f'Best: {best_f1:.4f}')\n",
    "axes[2].set_title('Macro F1 Score', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('F1 Score')\n",
    "axes[2].legend()\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CFG['BASE_DIR']}/training_curves.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"ğŸ’¾ í•™ìŠµ ê³¡ì„  ì €ì¥: {CFG['BASE_DIR']}/training_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. í‹€ë¦° ì´ë¯¸ì§€ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best ëª¨ë¸ ë¡œë“œ\n",
    "model.load_state_dict(torch.load(f\"{CFG['BASE_DIR']}/best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# ìµœì¢… ê²€ì¦\n",
    "val_loss, val_acc, val_f1, preds, targets = validate(\n",
    "    val_loader, model, loss_fn, CFG['DEVICE']\n",
    ")\n",
    "\n",
    "# í‹€ë¦° ì´ë¯¸ì§€ ë¶„ì„\n",
    "val_df = pd.read_csv(f\"{CFG['BASE_DIR']}/val_fold.csv\")\n",
    "\n",
    "analyze_wrong_predictions(\n",
    "    val_df=val_df,\n",
    "    preds_list=preds,\n",
    "    targets_list=targets,\n",
    "    img_dir=CFG['TRAIN_IMG_DIR'],\n",
    "    meta_df=meta_df,\n",
    "    save_path=f\"{CFG['BASE_DIR']}/wrong_predictions.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix ì‹œê°í™”\n",
    "cm = confusion_matrix(targets, preds)\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "plt.imshow(cm, cmap='Blues', interpolation='nearest')\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "plt.colorbar()\n",
    "\n",
    "# ì¶• ë ˆì´ë¸” (í´ë˜ìŠ¤ ì´ë¦„)\n",
    "tick_labels = [f\"{i}\\n{meta_df[meta_df['target']==i]['class_name'].values[0][:10]}\" \n",
    "               for i in range(CFG['NUM_CLASSES'])]\n",
    "plt.xticks(range(CFG['NUM_CLASSES']), tick_labels, rotation=45, ha='right', fontsize=8)\n",
    "plt.yticks(range(CFG['NUM_CLASSES']), tick_labels, fontsize=8)\n",
    "\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "\n",
    "# ê° ì…€ì— ìˆ«ì í‘œì‹œ\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, str(cm[i, j]), \n",
    "                ha='center', va='center',\n",
    "                color='white' if cm[i, j] > cm.max()/2 else 'black',\n",
    "                fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CFG['BASE_DIR']}/confusion_matrix.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nğŸ’¾ Confusion Matrix ì €ì¥: {CFG['BASE_DIR']}/confusion_matrix.png\")\n",
    "print(\"\\nğŸ’¡ Confusion Matrix í•´ì„:\")\n",
    "print(\"   - ëŒ€ê°ì„ : ì •í™•í•˜ê²Œ ì˜ˆì¸¡í•œ ê°œìˆ˜\")\n",
    "print(\"   - ëŒ€ê°ì„  ì™¸: ì˜ëª» ì˜ˆì¸¡í•œ ê°œìˆ˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Test ì˜ˆì¸¡ ë° ì œì¶œ íŒŒì¼ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best ëª¨ë¸ ë¡œë“œ (ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆì§€ë§Œ ì¬í™•ì¸)\n",
    "model.load_state_dict(torch.load(f\"{CFG['BASE_DIR']}/best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Test Dataset\n",
    "test_df.to_csv(f\"{CFG['BASE_DIR']}/test_temp.csv\", index=False)\n",
    "tst_dataset = ImageDataset(f\"{CFG['BASE_DIR']}/test_temp.csv\", CFG['TEST_IMG_DIR'], valid_transform)\n",
    "tst_loader = DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size=CFG['BATCH_SIZE'],\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "print(\"\\nğŸ”® Test ë°ì´í„° ì˜ˆì¸¡ ì¤‘...\")\n",
    "preds_list = []\n",
    "with torch.no_grad():\n",
    "    for image, _ in tqdm(tst_loader, desc='Predicting'):\n",
    "        image = image.to(CFG['DEVICE'])\n",
    "        preds = model(image)\n",
    "        preds_list.extend(preds.argmax(1).cpu().numpy())\n",
    "\n",
    "# ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "pred_df = pd.DataFrame({\n",
    "    'ID': test_df['ID'],\n",
    "    'target': preds_list\n",
    "})\n",
    "\n",
    "submission_path = f\"{CFG['BASE_DIR']}/submission.csv\"\n",
    "pred_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"\\nâœ… ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {submission_path}\")\n",
    "print(f\"\\nğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "print(pred_df.head(10))\n",
    "\n",
    "# ì˜ˆì¸¡ ë¶„í¬ í™•ì¸\n",
    "print(f\"\\nğŸ“ˆ ì˜ˆì¸¡ í´ë˜ìŠ¤ ë¶„í¬:\")\n",
    "pred_counts = pd.Series(preds_list).value_counts().sort_index()\n",
    "for class_id, count in pred_counts.items():\n",
    "    class_name = meta_df[meta_df['target'] == class_id]['class_name'].values[0]\n",
    "    print(f\"   Class {class_id:2d} ({class_name[:25]:25s}): {count:4d}ê°œ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
