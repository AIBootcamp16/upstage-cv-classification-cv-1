{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install transformers pillow -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œë“œ ê³ ì •\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config (EDA ê¸°ë°˜ ìµœì í™”)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    # Paths\n",
    "    'BASE_DIR': '/home/realtheai/cv_competetion',\n",
    "    'TRAIN_CSV': '/home/realtheai/cv_competetion/data/train.csv',\n",
    "    'TEST_CSV': '/home/realtheai/cv_competetion/data/sample_submission.csv',\n",
    "    'TRAIN_IMG_DIR': '/home/realtheai/cv_competetion/data/train',\n",
    "    'TEST_IMG_DIR': '/home/realtheai/cv_competetion/data/test',\n",
    "    \n",
    "    # Model\n",
    "    'MODEL_NAME': 'microsoft/dit-base-finetuned-rvlcdip',  # DiT - ë¬¸ì„œ íŠ¹í™”!\n",
    "    'NUM_CLASSES': 17,\n",
    "    \n",
    "    # Training\n",
    "    'IMG_SIZE': 224,  # DiT ê¸°ë³¸ í¬ê¸°\n",
    "    'BATCH_SIZE': 8,  # DiTëŠ” LayoutLMv3ë³´ë‹¤ ê°€ë²¼ì›€\n",
    "    'EPOCHS': 20,\n",
    "    'LR': 5e-5,       # Fine-tuning LR\n",
    "    'WEIGHT_DECAY': 0.01,\n",
    "    'WARMUP_RATIO': 0.1,\n",
    "    \n",
    "    # Device\n",
    "    'DEVICE': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š Configuration\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ëª¨ë¸: {CFG['MODEL_NAME']}\")\n",
    "print(f\"IMG_SIZE: {CFG['IMG_SIZE']}\")\n",
    "print(f\"BATCH_SIZE: {CFG['BATCH_SIZE']}\")\n",
    "print(f\"EPOCHS: {CFG['EPOCHS']}\")\n",
    "print(f\"Learning Rate: {CFG['LR']}\")\n",
    "print(f\"Device: {CFG['DEVICE']}\")\n",
    "print(\"=\"*60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DiT Image Processor ë¡œë“œ\n",
    "print(\"ğŸ”„ DiT Image Processor ë¡œë“œ ì¤‘...\")\n",
    "processor = AutoImageProcessor.from_pretrained(CFG['MODEL_NAME'])\n",
    "print(\"âœ… Processor ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "# DiT ëª¨ë¸ ë¡œë“œ\n",
    "print(\"\\nğŸ”„ DiT Model ë¡œë“œ ì¤‘...\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    CFG['MODEL_NAME'],\n",
    "    num_labels=CFG['NUM_CLASSES'],\n",
    "    ignore_mismatched_sizes=True\n",
    ").to(CFG['DEVICE'])\n",
    "print(\"âœ… Model ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ëª¨ë¸ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"ğŸ“Š ëª¨ë¸ í¬ê¸°: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiTDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_dir, processor):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.processor = processor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.df.iloc[idx]['ID'])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # DiT Processor: ì´ë¯¸ì§€ ìë™ ì²˜ë¦¬ (ì •ê·œí™”, ë¦¬ì‚¬ì´ì¦ˆ í¬í•¨)\n",
    "        encoding = self.processor(\n",
    "            images=image,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # ë°°ì¹˜ ì°¨ì› ì œê±°\n",
    "        encoding = {k: v.squeeze(0) for k, v in encoding.items()}\n",
    "        \n",
    "        if 'target' in self.df.columns:\n",
    "            encoding['labels'] = torch.tensor(self.df.iloc[idx]['target'], dtype=torch.long)\n",
    "        \n",
    "        return encoding\n",
    "\n",
    "print(\"âœ… DiTDataset í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë“œ\n",
    "train_df = pd.read_csv(CFG['TRAIN_CSV'])\n",
    "test_df = pd.read_csv(CFG['TEST_CSV'])\n",
    "\n",
    "# Train/Validation Split\n",
    "train_df, val_df = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=train_df['target']\n",
    ")\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ\")\n",
    "print(f\"   - Train: {len(train_df)}ê°œ\")\n",
    "print(f\"   - Validation: {len(val_df)}ê°œ\")\n",
    "print(f\"   - Test: {len(test_df)}ê°œ\")\n",
    "print(f\"   - í´ë˜ìŠ¤: {CFG['NUM_CLASSES']}ê°œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate í•¨ìˆ˜ ì •ì˜\n",
    "def collate_fn(batch):\n",
    "    \"\"\"ë°°ì¹˜ ë°ì´í„° ì²˜ë¦¬\"\"\"\n",
    "    batch_dict = {}\n",
    "    \n",
    "    for key in batch[0].keys():\n",
    "        batch_dict[key] = torch.stack([item[key] for item in batch])\n",
    "    \n",
    "    return batch_dict\n",
    "\n",
    "# Dataset ìƒì„±\n",
    "train_dataset = DiTDataset(CFG['TRAIN_CSV'], CFG['TRAIN_IMG_DIR'], processor)\n",
    "train_dataset.df = train_df.reset_index(drop=True)\n",
    "\n",
    "val_dataset = DiTDataset(CFG['TRAIN_CSV'], CFG['TRAIN_IMG_DIR'], processor)\n",
    "val_dataset.df = val_df.reset_index(drop=True)\n",
    "\n",
    "test_dataset = DiTDataset(CFG['TEST_CSV'], CFG['TEST_IMG_DIR'], processor)\n",
    "\n",
    "# DataLoader ìƒì„±\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CFG['BATCH_SIZE'],\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CFG['BATCH_SIZE'],\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CFG['BATCH_SIZE'],\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "print(\"âœ… DataLoader ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"   - Train batches: {len(train_loader)}\")\n",
    "print(f\"   - Val batches: {len(val_loader)}\")\n",
    "print(f\"   - Test batches: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer & Scheduler\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=CFG['LR'],\n",
    "    weight_decay=CFG['WEIGHT_DECAY']\n",
    ")\n",
    "\n",
    "total_steps = len(train_loader) * CFG['EPOCHS']\n",
    "warmup_steps = int(total_steps * CFG['WARMUP_RATIO'])\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(\"âœ… Optimizer & Scheduler ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"   - Total steps: {total_steps}\")\n",
    "print(f\"   - Warmup steps: {warmup_steps}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, scheduler, device):\n",
    "    \"\"\"1 Epoch í•™ìŠµ\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Training\")\n",
    "    for batch in pbar:\n",
    "        # GPUë¡œ ì´ë™\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "def validate(model, loader, device):\n",
    "    \"\"\"Validation\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Validation\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            preds = outputs.logits.argmax(dim=-1)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch['labels'].cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    return avg_loss, accuracy, f1, all_preds, all_labels\n",
    "\n",
    "print(\"âœ… í•™ìŠµ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ ê¸°ë¡\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'val_f1': []\n",
    "}\n",
    "\n",
    "best_f1 = 0\n",
    "best_epoch = 0\n",
    "val_preds = None\n",
    "val_targets = None\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸš€ í•™ìŠµ ì‹œì‘!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for epoch in range(1, CFG['EPOCHS'] + 1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, CFG['DEVICE'])\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, val_f1, preds, targets = validate(model, val_loader, CFG['DEVICE'])\n",
    "    \n",
    "    # ê¸°ë¡\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_f1'].append(val_f1)\n",
    "    \n",
    "    # Best ëª¨ë¸ ì €ì¥\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        best_epoch = epoch\n",
    "        val_preds = preds\n",
    "        val_targets = targets\n",
    "        torch.save(model.state_dict(), f\"{CFG['BASE_DIR']}/07_best_model.pth\")\n",
    "        print(f\"   âœ… Best ëª¨ë¸ ì €ì¥! (F1: {best_f1:.4f})\")\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n[Epoch {epoch}/{CFG['EPOCHS']}] {elapsed_time:.1f}s\")\n",
    "    print(f\"   Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"   Val Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f}\")\n",
    "    print(f\"   Best F1: {best_f1:.4f} (Epoch {best_epoch})\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "print(\"\\nğŸ‰ í•™ìŠµ ì™„ë£Œ!\")\n",
    "print(f\"Best F1: {best_f1:.4f} (Epoch {best_epoch})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ ê³¡ì„ \n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', marker='o')\n",
    "axes[0].set_title('Loss Curve', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history['val_acc'], label='Val Accuracy', marker='o', color='green')\n",
    "axes[1].set_title('Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# F1 Score\n",
    "axes[2].plot(history['val_f1'], label='Val F1', marker='o', color='red')\n",
    "axes[2].axhline(y=best_f1, color='r', linestyle='--', alpha=0.5, label=f'Best F1: {best_f1:.4f}')\n",
    "axes[2].set_title('Validation F1 Score', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('F1 Score')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CFG['BASE_DIR']}/07_training_curves.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… í•™ìŠµ ê³¡ì„  ì €ì¥: 07_training_curves.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrong Predictions Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_wrong_predictions(val_df, preds_list, targets_list, img_dir, meta_df=None, save_path=None):\n",
    "    \"\"\"í‹€ë¦° ì´ë¯¸ì§€ ì‹œê°í™” ë° íŒ¨í„´ ë¶„ì„\"\"\"\n",
    "    # í‹€ë¦° ì¸ë±ìŠ¤ ì°¾ê¸°\n",
    "    wrong_indices = [i for i, (pred, target) in enumerate(zip(preds_list, targets_list)) if pred != target]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ“Š ê²€ì¦ ê²°ê³¼ ë¶„ì„\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"   ì „ì²´: {len(preds_list)}ê°œ\")\n",
    "    print(f\"   ì •ë‹µ: {len(preds_list) - len(wrong_indices)}ê°œ\")\n",
    "    print(f\"   ì˜¤ë‹µ: {len(wrong_indices)}ê°œ ({len(wrong_indices)/len(preds_list)*100:.1f}%)\")\n",
    "    print(f\"   ì •í™•ë„: {(len(preds_list) - len(wrong_indices))/len(preds_list)*100:.1f}%\")\n",
    "    \n",
    "    if len(wrong_indices) == 0:\n",
    "        print(\"\\nğŸ‰ ëª¨ë“  ì˜ˆì¸¡ì´ ì •í™•í•©ë‹ˆë‹¤!\")\n",
    "        return\n",
    "    \n",
    "    # í´ë˜ìŠ¤ë³„ ì˜¤ë¥˜ ë¶„ì„\n",
    "    wrong_by_true_class = {}\n",
    "    for idx in wrong_indices:\n",
    "        true_class = targets_list[idx]\n",
    "        if true_class not in wrong_by_true_class:\n",
    "            wrong_by_true_class[true_class] = []\n",
    "        wrong_by_true_class[true_class].append(idx)\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ í´ë˜ìŠ¤ë³„ ì˜¤ë‹µ ë¶„ì„:\")\n",
    "    for class_id in sorted(wrong_by_true_class.keys()):\n",
    "        count = len(wrong_by_true_class[class_id])\n",
    "        if meta_df is not None:\n",
    "            class_name = meta_df[meta_df['target'] == class_id]['class_name'].values[0]\n",
    "            print(f\"   Class {class_id:2d} ({class_name[:20]:20s}): {count:2d}ê°œ ì˜¤ë‹µ\")\n",
    "        else:\n",
    "            print(f\"   Class {class_id:2d}: {count:2d}ê°œ ì˜¤ë‹µ\")\n",
    "    \n",
    "    # í‹€ë¦° ì´ë¯¸ì§€ ì‹œê°í™” (12ê°œ)\n",
    "    if save_path:\n",
    "        n_show = min(12, len(wrong_indices))\n",
    "        fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, idx in enumerate(wrong_indices[:n_show]):\n",
    "            img_name = val_df.iloc[idx]['ID']\n",
    "            img_path = os.path.join(img_dir, img_name)\n",
    "            \n",
    "            if os.path.exists(img_path):\n",
    "                img = Image.open(img_path)\n",
    "                axes[i].imshow(img)\n",
    "                \n",
    "                true_label = f\"True: {targets_list[idx]}\"\n",
    "                pred_label = f\"Pred: {preds_list[idx]}\"\n",
    "                \n",
    "                if meta_df is not None:\n",
    "                    true_class = meta_df[meta_df['target'] == targets_list[idx]]['class_name'].values[0]\n",
    "                    pred_class = meta_df[meta_df['target'] == preds_list[idx]]['class_name'].values[0]\n",
    "                    true_label += f\"\\n({true_class[:15]})\"\n",
    "                    pred_label += f\"\\n({pred_class[:15]})\"\n",
    "                \n",
    "                axes[i].set_title(\n",
    "                    f\"{true_label}\\n{pred_label}\",\n",
    "                    fontsize=9,\n",
    "                    color='red',\n",
    "                    fontweight='bold'\n",
    "                )\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        # ë¹ˆ subplot ìˆ¨ê¸°ê¸°\n",
    "        for i in range(n_show, 12):\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(f\"\\nğŸ’¾ í‹€ë¦° ì´ë¯¸ì§€ ì €ì¥: {save_path}\")\n",
    "\n",
    "print(\"âœ… analyze_wrong_predictions í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CFG['BASE_DIR']}/training_curves.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta.csv ë¡œë“œ\n",
    "meta_df = pd.read_csv(f\"{CFG['BASE_DIR']}/data/meta.csv\")\n",
    "\n",
    "# Wrong Predictions ë¶„ì„\n",
    "analyze_wrong_predictions(\n",
    "    val_dataset.df,\n",
    "    val_preds,\n",
    "    val_targets,\n",
    "    CFG['TRAIN_IMG_DIR'],\n",
    "    meta_df=meta_df,\n",
    "    save_path=f\"{CFG['BASE_DIR']}/wrong_predictions.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(val_targets, val_preds)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "# ì¶• ë ˆì´ë¸” (í´ë˜ìŠ¤ ì´ë¦„)\n",
    "tick_labels = [f\"{i}\\n{meta_df[meta_df['target']==i]['class_name'].values[0][:10]}\" \n",
    "               for i in range(CFG['NUM_CLASSES'])]\n",
    "plt.xticks(np.arange(CFG['NUM_CLASSES']) + 0.5, tick_labels, rotation=45, ha='right', fontsize=8)\n",
    "plt.yticks(np.arange(CFG['NUM_CLASSES']) + 0.5, tick_labels, fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CFG['BASE_DIR']}/confusion_matrix.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference & Submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best ëª¨ë¸ ë¡œë“œ\n",
    "model.load_state_dict(torch.load(f\"{CFG['BASE_DIR']}/best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Test ì˜ˆì¸¡\n",
    "preds_list = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Inference\"):\n",
    "        # labels ì œê±° (testì—ëŠ” ì—†ìŒ)\n",
    "        batch = {k: v.to(CFG['DEVICE']) for k, v in batch.items() if k != 'labels'}\n",
    "        \n",
    "        outputs = model(**batch)\n",
    "        preds = outputs.logits.argmax(dim=-1)\n",
    "        preds_list.extend(preds.cpu().numpy())\n",
    "\n",
    "# ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "submission = pd.read_csv(CFG['TEST_CSV'])\n",
    "submission['target'] = preds_list\n",
    "submission.to_csv(f\"{CFG['BASE_DIR']}/submission.csv\", index=False)\n",
    "# ì˜ˆì¸¡ ë¶„í¬\n",
    "print(f\"\\nğŸ“ˆ Test í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ ë¶„í¬:\")\n",
    "pred_counts = pd.Series(preds_list).value_counts().sort_index()\n",
    "for class_id, count in pred_counts.items():\n",
    "    class_name = meta_df[meta_df['target'] == class_id]['class_name'].values[0]\n",
    "    print(f\"   Class {class_id:2d} ({class_name[:25]:25s}): {count:4d}ê°œ\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
